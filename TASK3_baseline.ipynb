{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb57905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43e36b",
   "metadata": {},
   "source": [
    "let's start with loading the dataset and storing them as dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ad7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3 = pd.read_csv(\"data\\\\gpt3.csv\")\n",
    "instruct = pd.read_csv(\"data\\\\instruct.csv\")\n",
    "new_ctrl = pd.read_csv(\"data\\\\new_ctrl.csv\")\n",
    "new_fair = pd.read_csv(\"data\\\\new_fair.csv\")\n",
    "new_gpt = pd.read_csv(\"data\\\\new_gpt.csv\")\n",
    "new_gpt2 = pd.read_csv(\"data\\\\new_gpt2.csv\")\n",
    "new_grover = pd.read_csv(\"data\\\\new_grover.csv\")\n",
    "new_human = pd.read_csv(\"data\\\\new_human.csv\")\n",
    "new_pplm = pd.read_csv(\"data\\\\new_pplm.csv\")\n",
    "new_xlm = pd.read_csv(\"data\\\\new_xlm.csv\")\n",
    "new_xlnet = pd.read_csv(\"data\\\\new_xlnet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5490b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Generation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>latest headlines on cnn business tl;dr the u.s...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>china wants to take a victory lap over its han...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>coronavirus disinformation creates challenges ...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>china coronavirus: eating wild animals made il...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>china's economy could shrink for the first tim...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         Generation label\n",
       "0           0  latest headlines on cnn business tl;dr the u.s...  ctrl\n",
       "1           1  china wants to take a victory lap over its han...  ctrl\n",
       "2           2  coronavirus disinformation creates challenges ...  ctrl\n",
       "3           3  china coronavirus: eating wild animals made il...  ctrl\n",
       "4           4  china's economy could shrink for the first tim...  ctrl"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ctrl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe228bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latest headlines on cnn business tl;dr the u.s...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>china wants to take a victory lap over its han...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus disinformation creates challenges ...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>china coronavirus: eating wild animals made il...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>china's economy could shrink for the first tim...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>how much of your body is your own? a. i think ...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>how do you keep a space station clean? q. what...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>the city where you pay a year's rent up front ...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>the bbc app gives you the best of bbc wherever...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>learn how the bbc is working to strengthen tru...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1066 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Generation label\n",
       "0     latest headlines on cnn business tl;dr the u.s...  ctrl\n",
       "1     china wants to take a victory lap over its han...  ctrl\n",
       "2     coronavirus disinformation creates challenges ...  ctrl\n",
       "3     china coronavirus: eating wild animals made il...  ctrl\n",
       "4     china's economy could shrink for the first tim...  ctrl\n",
       "...                                                 ...   ...\n",
       "1061  how much of your body is your own? a. i think ...  ctrl\n",
       "1062  how do you keep a space station clean? q. what...  ctrl\n",
       "1063  the city where you pay a year's rent up front ...  ctrl\n",
       "1064  the bbc app gives you the best of bbc wherever...  ctrl\n",
       "1065  learn how the bbc is working to strengthen tru...  ctrl\n",
       "\n",
       "[1066 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ctrl.iloc[ : , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8326577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>prompt</th>\n",
       "      <th>Generation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Latest Headlines on CNN Business</td>\n",
       "      <td>1. Ford recalling 373,000 cars in the US over ...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>China wants to take a victory lap over its han...</td>\n",
       "      <td>October 27, 2016, 10:06 p.m.China has issued a...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coronavirus disinformation creates challenges ...</td>\n",
       "      <td>The Chinese government has been vocal about it...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>China coronavirus: Eating wild animals made il...</td>\n",
       "      <td>The World Health Organization (WHO) says that ...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>China's economy could shrink for the first tim...</td>\n",
       "      <td>A new study by the Oxford Economics research f...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             prompt  \\\n",
       "0           0                   Latest Headlines on CNN Business   \n",
       "1           1  China wants to take a victory lap over its han...   \n",
       "2           2  Coronavirus disinformation creates challenges ...   \n",
       "3           3  China coronavirus: Eating wild animals made il...   \n",
       "4           4  China's economy could shrink for the first tim...   \n",
       "\n",
       "                                          Generation label  \n",
       "0  1. Ford recalling 373,000 cars in the US over ...  GPT3  \n",
       "1  October 27, 2016, 10:06 p.m.China has issued a...  GPT3  \n",
       "2  The Chinese government has been vocal about it...  GPT3  \n",
       "3  The World Health Organization (WHO) says that ...  GPT3  \n",
       "4  A new study by the Oxford Economics research f...  GPT3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716d5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3 = gpt3.iloc[ : , 2:]\n",
    "instruct = instruct.iloc[ : , 2:]\n",
    "new_ctrl = new_ctrl.iloc[ : , 1:]\n",
    "new_fair = new_fair.iloc[ : , 1:]\n",
    "new_gpt = new_gpt.iloc[ : , 1:]\n",
    "new_gpt2 = new_gpt2.iloc[ : , 1:]\n",
    "new_grover = new_grover.iloc[ : , 1:]\n",
    "new_human = new_human.iloc[ : , 1:]\n",
    "new_pplm = new_pplm.iloc[ : , 1:]\n",
    "new_xlm = new_xlm.iloc[ : , 1:]\n",
    "new_xlnet = new_xlnet.iloc[ : , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427fe469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mount Everest, the world's highest mountain, was closed to climbers Thursday due to fears of a coronavirus pandemic.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3['Generation'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b60dc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Ford recalling 373,000 cars in the US over ...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>October 27, 2016, 10:06 p.m.China has issued a...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Chinese government has been vocal about it...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The World Health Organization (WHO) says that ...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A new study by the Oxford Economics research f...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Generation label\n",
       "0  1. Ford recalling 373,000 cars in the US over ...  GPT3\n",
       "1  October 27, 2016, 10:06 p.m.China has issued a...  GPT3\n",
       "2  The Chinese government has been vocal about it...  GPT3\n",
       "3  The World Health Organization (WHO) says that ...  GPT3\n",
       "4  A new study by the Oxford Economics research f...  GPT3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5167316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_the_text(data):\n",
    "    clean_data = []\n",
    "    for i in list(data['Generation']):\n",
    "        # Replace all the specified patterns with spaces\n",
    "        text = re.sub('[^A-Za-z0-9]+|<unk>|\\n| \\ |<UNK>|News|<eos>|<eod>|<eop>', ' ', str(i))\n",
    "        # Replace consecutive whitespaces with a single space\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        # Remove leading/trailing whitespaces\n",
    "        text = text.strip()\n",
    "        clean_data.append(text)\n",
    "    \n",
    "    # Create a new DataFrame with cleaned texts and original labels\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ce9aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3['Generation'] = clean_the_text(gpt3)\n",
    "instruct['Generation'] = clean_the_text(instruct)\n",
    "new_ctrl['Generation'] = clean_the_text(new_ctrl)\n",
    "new_fair['Generation'] = clean_the_text(new_fair)\n",
    "new_gpt['Generation'] = clean_the_text(new_gpt)\n",
    "new_gpt2['Generation'] = clean_the_text(new_gpt2)\n",
    "new_grover['Generation'] = clean_the_text(new_grover)\n",
    "new_pplm['Generation'] = clean_the_text(new_pplm)\n",
    "new_xlm['Generation'] = clean_the_text(new_xlm)\n",
    "new_xlnet['Generation'] = clean_the_text(new_xlnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60e904",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43257949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(data):\n",
    "    word_lengths = []\n",
    "    sentence_lengths = []\n",
    "#     data = data['Generation']\n",
    "    # Tokenize each text in the data\n",
    "    for text in data:\n",
    "#         print(text)\n",
    "        \n",
    "        \n",
    "        words = word_tokenize(text)\n",
    "        if len(words) == 0:\n",
    "            continue\n",
    "        word_lengths.append(len(words))\n",
    "        sentences = sent_tokenize(text)\n",
    "        if len(sentences) == 0:\n",
    "            continue\n",
    "        sentence_lengths.append(len(sentences))\n",
    "#     print(word_lengths)\n",
    "#     print(sentence_lengths)\n",
    "    \n",
    "    # Filter out any lengths that are more than 2 standard deviations away from the mean\n",
    "    mean_word_length = np.mean(word_lengths)\n",
    "    std_word_length = np.std(word_lengths)\n",
    "    new_word_lengths = [x for x in word_lengths if (x > mean_word_length - 2 * std_word_length)]\n",
    "    new_word_lengths = [x for x in new_word_lengths if (x < mean_word_length + 2 * std_word_length)]\n",
    "    \n",
    "    mean_sentence_length = np.mean(sentence_lengths)\n",
    "    std_sentence_length = np.std(sentence_lengths)\n",
    "    new_sentence_lengths = [x for x in sentence_lengths if (x > mean_sentence_length - 2 * std_sentence_length)]\n",
    "    new_sentence_lengths = [x for x in new_sentence_lengths if (x < mean_sentence_length + 2 * std_sentence_length)]\n",
    "    \n",
    "    # Return a DataFrame with the statistics\n",
    "    return pd.DataFrame({'Avg_word': np.mean(new_word_lengths), \n",
    "                         'SD_word': np.std(new_word_lengths),\n",
    "                         'Avg_sent': np.mean(new_sentence_lengths),\n",
    "                         'SD_sent': np.std(new_sentence_lengths)}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5759dc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.340932</td>\n",
       "      <td>72.792486</td>\n",
       "      <td>3.385602</td>\n",
       "      <td>2.590803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Avg_word    SD_word  Avg_sent   SD_sent\n",
       "0  97.340932  72.792486  3.385602  2.590803"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "gpt3 = gpt3.replace(np.nan,' ',regex=True)\n",
    "\n",
    "statistics(gpt3['Generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f6ebf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133.629191</td>\n",
       "      <td>69.392365</td>\n",
       "      <td>5.165029</td>\n",
       "      <td>2.696187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avg_word    SD_word  Avg_sent   SD_sent\n",
       "0  133.629191  69.392365  5.165029  2.696187"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "instruct = instruct.replace(np.nan,' ',regex=True)\n",
    "\n",
    "statistics(instruct['Generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92cba67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>528.272115</td>\n",
       "      <td>69.105285</td>\n",
       "      <td>30.466143</td>\n",
       "      <td>16.258389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avg_word    SD_word   Avg_sent    SD_sent\n",
       "0  528.272115  69.105285  30.466143  16.258389"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# instruct = instruct.replace(np.nan,' ',regex=True)\n",
    "\n",
    "statistics(new_ctrl['Generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74ffe712",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fair_stats = statistics(new_fair['Generation'])\n",
    "new_gpt_stats = statistics(new_gpt['Generation'])\n",
    "new_gpt2_stats = statistics(new_gpt2['Generation'])\n",
    "new_grover_stats = statistics(new_grover['Generation'])\n",
    "new_human_stats = statistics(new_human['Generation'])\n",
    "new_pplm_stats = statistics(new_pplm['Generation'])\n",
    "new_xlm_stats = statistics(new_xlm['Generation'])\n",
    "new_xlnet_stats = statistics(new_xlnet['Generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1bdcaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>450.260954</td>\n",
       "      <td>24.602548</td>\n",
       "      <td>19.835481</td>\n",
       "      <td>4.641423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avg_word    SD_word   Avg_sent   SD_sent\n",
       "0  450.260954  24.602548  19.835481  4.641423"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fair_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47dce396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>431.950147</td>\n",
       "      <td>8.786401</td>\n",
       "      <td>33.581188</td>\n",
       "      <td>4.88986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avg_word   SD_word   Avg_sent  SD_sent\n",
       "0  431.950147  8.786401  33.581188  4.88986"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gpt_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "586b1173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452.716814</td>\n",
       "      <td>28.46783</td>\n",
       "      <td>20.632278</td>\n",
       "      <td>6.944668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avg_word   SD_word   Avg_sent   SD_sent\n",
       "0  452.716814  28.46783  20.632278  6.944668"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gpt2_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f94953fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552.016053</td>\n",
       "      <td>196.044181</td>\n",
       "      <td>21.407336</td>\n",
       "      <td>8.911193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avg_word     SD_word   Avg_sent   SD_sent\n",
       "0  552.016053  196.044181  21.407336  8.911193"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_grover_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bede6fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>830.470302</td>\n",
       "      <td>789.914863</td>\n",
       "      <td>33.546251</td>\n",
       "      <td>32.815327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avg_word     SD_word   Avg_sent    SD_sent\n",
       "0  830.470302  789.914863  33.546251  32.815327"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_human_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52d83e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>471.462572</td>\n",
       "      <td>19.366528</td>\n",
       "      <td>15.320717</td>\n",
       "      <td>4.387224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avg_word    SD_word   Avg_sent   SD_sent\n",
       "0  471.462572  19.366528  15.320717  4.387224"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pplm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e5be4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>445.492567</td>\n",
       "      <td>20.003473</td>\n",
       "      <td>3.815739</td>\n",
       "      <td>1.256317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avg_word    SD_word  Avg_sent   SD_sent\n",
       "0  445.492567  20.003473  3.815739  1.256317"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_xlm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a2d59714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_word</th>\n",
       "      <th>SD_word</th>\n",
       "      <th>Avg_sent</th>\n",
       "      <th>SD_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>491.721068</td>\n",
       "      <td>13.047556</td>\n",
       "      <td>4.707956</td>\n",
       "      <td>1.562819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avg_word    SD_word  Avg_sent   SD_sent\n",
       "0  491.721068  13.047556  4.707956  1.562819"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_xlnet_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d124fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5151bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a3b5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b8603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ff863f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Ford recalling 373,000 cars in the US over ...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>October 27, 2016, 10:06 p.m.China has issued a...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Chinese government has been vocal about it...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The World Health Organization (WHO) says that ...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A new study by the Oxford Economics research f...</td>\n",
       "      <td>GPT3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Generation label\n",
       "0  1. Ford recalling 373,000 cars in the US over ...  GPT3\n",
       "1  October 27, 2016, 10:06 p.m.China has issued a...  GPT3\n",
       "2  The Chinese government has been vocal about it...  GPT3\n",
       "3  The World Health Organization (WHO) says that ...  GPT3\n",
       "4  A new study by the Oxford Economics research f...  GPT3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4dcd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\girid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43691882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "054a5458",
   "metadata": {},
   "source": [
    "## Combined Dataset for Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dcf9a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([new_ctrl,new_fair, new_gpt, new_gpt2, new_grover, new_xlm, new_xlnet, new_pplm, new_human, gpt3, instruct])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e80dbef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11726"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0df31acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "634e48e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11726"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "070419a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2c33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8e131da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_int'] = pd.Categorical(df['label']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df98ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b95329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "33c64093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['human', 'instructgpt', 'pplm', 'gpt', 'xlm', 'xlnet', 'gpt2',\n",
       "       'fair', 'ctrl', 'gpt3', 'grover'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6aad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ac254e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "      <th>label</th>\n",
       "      <th>class_categorical</th>\n",
       "      <th>label_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Local News get the news that's local to you</td>\n",
       "      <td>human</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:The number of confirmed cases of coronavirus ...</td>\n",
       "      <td>instructgpt</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>| | how ancient egyptian cosmetics influenced ...</td>\n",
       "      <td>pplm</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is it allergies, the flu or the coronavirus? h...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>don't toss this food scrap (it could be vastly...</td>\n",
       "      <td>xlm</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a coronavirus outbreak could be devastating fo...</td>\n",
       "      <td>xlnet</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i forgave my father for walking out on me. i h...</td>\n",
       "      <td>xlm</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>things to do indoors with your children the fo...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coronavirus: english local elections postponed...</td>\n",
       "      <td>fair</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>split by trump's travel ban, a family races to...</td>\n",
       "      <td>ctrl</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a bipartisan buttigieg effect? the people of t...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>coronavirus could hurt boeing more than the 73...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>President Trump's unannounced hospital visit o...</td>\n",
       "      <td>instructgpt</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Donald Trump's first efforts to control the sp...</td>\n",
       "      <td>instructgpt</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>littleton school uses heart monitors to help s...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>branding news outlets as foreign agents won't ...</td>\n",
       "      <td>xlm</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>we're not talking to our girls enough about mo...</td>\n",
       "      <td>fair</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hong kong protests: how unrest criminalized a ...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Know which VP tackled a Heisman Trophy winner?...</td>\n",
       "      <td>human</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C coronavirus is a type of virus that can caus...</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>brave. groundbreaking. badass. notorious: the ...</td>\n",
       "      <td>fair</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>more than pho: 5 dishes every hanoi visitor ne...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aloo masala (spiced potatoes) recipe for the p...</td>\n",
       "      <td>ctrl</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ryugyong Hotel: The story of North Korea's 'Ho...</td>\n",
       "      <td>grover</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>brisbane car fire: woman and three children ki...</td>\n",
       "      <td>fair</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>students at olin college held a 'fauxmencement...</td>\n",
       "      <td>ctrl</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Reports have surfaced that a staff member of t...</td>\n",
       "      <td>instructgpt</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>| | opinion | the pandemic vs. the president b...</td>\n",
       "      <td>pplm</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>looks like the donald trump show is getting re...</td>\n",
       "      <td>ctrl</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Photographer Daniel Arnold visits the center a...</td>\n",
       "      <td>grover</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Generation        label  \\\n",
       "0         Local News get the news that's local to you        human   \n",
       "1   :The number of confirmed cases of coronavirus ...  instructgpt   \n",
       "2   | | how ancient egyptian cosmetics influenced ...         pplm   \n",
       "3   is it allergies, the flu or the coronavirus? h...          gpt   \n",
       "4   don't toss this food scrap (it could be vastly...          xlm   \n",
       "5   a coronavirus outbreak could be devastating fo...        xlnet   \n",
       "6   i forgave my father for walking out on me. i h...          xlm   \n",
       "7   things to do indoors with your children the fo...         gpt2   \n",
       "8   coronavirus: english local elections postponed...         fair   \n",
       "9   split by trump's travel ban, a family races to...         ctrl   \n",
       "10  a bipartisan buttigieg effect? the people of t...          gpt   \n",
       "11  coronavirus could hurt boeing more than the 73...          gpt   \n",
       "12  President Trump's unannounced hospital visit o...  instructgpt   \n",
       "13  Donald Trump's first efforts to control the sp...  instructgpt   \n",
       "14  littleton school uses heart monitors to help s...         gpt2   \n",
       "15  branding news outlets as foreign agents won't ...          xlm   \n",
       "16  we're not talking to our girls enough about mo...         fair   \n",
       "17  hong kong protests: how unrest criminalized a ...          gpt   \n",
       "18  Know which VP tackled a Heisman Trophy winner?...        human   \n",
       "19  C coronavirus is a type of virus that can caus...         gpt3   \n",
       "20  brave. groundbreaking. badass. notorious: the ...         fair   \n",
       "21  more than pho: 5 dishes every hanoi visitor ne...          gpt   \n",
       "22  aloo masala (spiced potatoes) recipe for the p...         ctrl   \n",
       "23  Ryugyong Hotel: The story of North Korea's 'Ho...       grover   \n",
       "24  brisbane car fire: woman and three children ki...         fair   \n",
       "25  students at olin college held a 'fauxmencement...         ctrl   \n",
       "26  Reports have surfaced that a staff member of t...  instructgpt   \n",
       "27  | | opinion | the pandemic vs. the president b...         pplm   \n",
       "28  looks like the donald trump show is getting re...         ctrl   \n",
       "29  Photographer Daniel Arnold visits the center a...       grover   \n",
       "\n",
       "    class_categorical  label_int  \n",
       "0                   7          6  \n",
       "1                   8          7  \n",
       "2                   9          8  \n",
       "3                   4          2  \n",
       "4                  10          9  \n",
       "5                  11         10  \n",
       "6                  10          9  \n",
       "7                   5          3  \n",
       "8                   3          1  \n",
       "9                   2          0  \n",
       "10                  4          2  \n",
       "11                  4          2  \n",
       "12                  8          7  \n",
       "13                  8          7  \n",
       "14                  5          3  \n",
       "15                 10          9  \n",
       "16                  3          1  \n",
       "17                  4          2  \n",
       "18                  7          6  \n",
       "19                  0          4  \n",
       "20                  3          1  \n",
       "21                  4          2  \n",
       "22                  2          0  \n",
       "23                  6          5  \n",
       "24                  3          1  \n",
       "25                  2          0  \n",
       "26                  8          7  \n",
       "27                  9          8  \n",
       "28                  2          0  \n",
       "29                  6          5  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa04cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df = df[['Generation','label','label_int']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74c156e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Task3.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8abeef5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "      <th>label</th>\n",
       "      <th>label_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Local News get the news that's local to you</td>\n",
       "      <td>human</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:The number of confirmed cases of coronavirus ...</td>\n",
       "      <td>instructgpt</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>| | how ancient egyptian cosmetics influenced ...</td>\n",
       "      <td>pplm</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is it allergies, the flu or the coronavirus? h...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>don't toss this food scrap (it could be vastly...</td>\n",
       "      <td>xlm</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a coronavirus outbreak could be devastating fo...</td>\n",
       "      <td>xlnet</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i forgave my father for walking out on me. i h...</td>\n",
       "      <td>xlm</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>things to do indoors with your children the fo...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coronavirus: english local elections postponed...</td>\n",
       "      <td>fair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>split by trump's travel ban, a family races to...</td>\n",
       "      <td>ctrl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a bipartisan buttigieg effect? the people of t...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>coronavirus could hurt boeing more than the 73...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>President Trump's unannounced hospital visit o...</td>\n",
       "      <td>instructgpt</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Donald Trump's first efforts to control the sp...</td>\n",
       "      <td>instructgpt</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>littleton school uses heart monitors to help s...</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>branding news outlets as foreign agents won't ...</td>\n",
       "      <td>xlm</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>we're not talking to our girls enough about mo...</td>\n",
       "      <td>fair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hong kong protests: how unrest criminalized a ...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Know which VP tackled a Heisman Trophy winner?...</td>\n",
       "      <td>human</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C coronavirus is a type of virus that can caus...</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>brave. groundbreaking. badass. notorious: the ...</td>\n",
       "      <td>fair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>more than pho: 5 dishes every hanoi visitor ne...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aloo masala (spiced potatoes) recipe for the p...</td>\n",
       "      <td>ctrl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ryugyong Hotel: The story of North Korea's 'Ho...</td>\n",
       "      <td>grover</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>brisbane car fire: woman and three children ki...</td>\n",
       "      <td>fair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>students at olin college held a 'fauxmencement...</td>\n",
       "      <td>ctrl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Reports have surfaced that a staff member of t...</td>\n",
       "      <td>instructgpt</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>| | opinion | the pandemic vs. the president b...</td>\n",
       "      <td>pplm</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>looks like the donald trump show is getting re...</td>\n",
       "      <td>ctrl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Photographer Daniel Arnold visits the center a...</td>\n",
       "      <td>grover</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Generation        label  label_int\n",
       "0         Local News get the news that's local to you        human          6\n",
       "1   :The number of confirmed cases of coronavirus ...  instructgpt          7\n",
       "2   | | how ancient egyptian cosmetics influenced ...         pplm          8\n",
       "3   is it allergies, the flu or the coronavirus? h...          gpt          2\n",
       "4   don't toss this food scrap (it could be vastly...          xlm          9\n",
       "5   a coronavirus outbreak could be devastating fo...        xlnet         10\n",
       "6   i forgave my father for walking out on me. i h...          xlm          9\n",
       "7   things to do indoors with your children the fo...         gpt2          3\n",
       "8   coronavirus: english local elections postponed...         fair          1\n",
       "9   split by trump's travel ban, a family races to...         ctrl          0\n",
       "10  a bipartisan buttigieg effect? the people of t...          gpt          2\n",
       "11  coronavirus could hurt boeing more than the 73...          gpt          2\n",
       "12  President Trump's unannounced hospital visit o...  instructgpt          7\n",
       "13  Donald Trump's first efforts to control the sp...  instructgpt          7\n",
       "14  littleton school uses heart monitors to help s...         gpt2          3\n",
       "15  branding news outlets as foreign agents won't ...          xlm          9\n",
       "16  we're not talking to our girls enough about mo...         fair          1\n",
       "17  hong kong protests: how unrest criminalized a ...          gpt          2\n",
       "18  Know which VP tackled a Heisman Trophy winner?...        human          6\n",
       "19  C coronavirus is a type of virus that can caus...         gpt3          4\n",
       "20  brave. groundbreaking. badass. notorious: the ...         fair          1\n",
       "21  more than pho: 5 dishes every hanoi visitor ne...          gpt          2\n",
       "22  aloo masala (spiced potatoes) recipe for the p...         ctrl          0\n",
       "23  Ryugyong Hotel: The story of North Korea's 'Ho...       grover          5\n",
       "24  brisbane car fire: woman and three children ki...         fair          1\n",
       "25  students at olin college held a 'fauxmencement...         ctrl          0\n",
       "26  Reports have surfaced that a staff member of t...  instructgpt          7\n",
       "27  | | opinion | the pandemic vs. the president b...         pplm          8\n",
       "28  looks like the donald trump show is getting re...         ctrl          0\n",
       "29  Photographer Daniel Arnold visits the center a...       grover          5"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b5632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b27009a",
   "metadata": {},
   "source": [
    "## Random Forest with TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2af8374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "04447b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c89c911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bc0593a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter, FixedLocator\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fbac871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data, label):\n",
    "            \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size = 0.2, random_state = 1234)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=1234,n_estimators=150,n_jobs=-1)\n",
    "#     clf = LogisticRegression(solver = 'lbfgs',multi_class='auto')\n",
    "    \n",
    "    v = TfidfVectorizer()\n",
    "    \n",
    "    train_corpus = X_train\n",
    "#     train_corpus = [[word.lower() for word in text.split()] for text in data]\n",
    "\n",
    "    test_corpus = X_test\n",
    "#     test_corpus = [\" \".join(x) for x in test_corpus]\n",
    "\n",
    "#     ax = axes.set_ylim([0,300])\n",
    "    train_vector = v.fit_transform(train_corpus)\n",
    "    test_vector = v.transform(test_corpus)\n",
    "    \n",
    "    fit = clf.fit(train_vector,y_train)\n",
    "    pred = clf.predict(test_vector)\n",
    "    \n",
    "#     # Instantiate the classification model and visualizer\n",
    "#     visualizer = ClassPredictionError(clf, classes= ['human', 'ctrl', 'gpt', 'gpt2', 'grover', 'xlm', 'xlnet', 'pplm', 'fair'])\n",
    "\n",
    "#     # Fit the training data to the visualizer\n",
    "#     visualizer.fit(train_vector, y_train)\n",
    "\n",
    "#     # Evaluate the model on the test data\n",
    "#     visualizer.score(test_vector, y_test)\n",
    "\n",
    "#     # Draw visualization\n",
    "#     visualizer.show()\n",
    "    \n",
    "    l=['ctrl','fair' ,'gpt', 'gpt2', 'gpt3', 'grover', 'human', 'instructgpt', 'pplm', 'xlm', 'xlnet']\n",
    "    matrix = confusion_matrix(y_test, pred, labels = l)\n",
    "    mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    print(classification_report(y_test, pred, labels = l,\n",
    "                                digits=4))\n",
    "    print('confusion matrix: ', mat)\n",
    "    \n",
    "    Accuracy = accuracy_score(y_test,pred)\n",
    "    F1 = f1_score(y_test, pred, average='macro')\n",
    "    print(\"Accuracy:\", Accuracy)\n",
    "    \n",
    "    rec = recall_score(y_test, pred, average='macro')\n",
    "    print('Recall: ', rec)\n",
    "    prec = precision_score(y_test, pred, average='macro')\n",
    "    print('Precision: ', prec)\n",
    "    \n",
    "    print('F1:', F1)\n",
    "    \n",
    "    return clf, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7abc59c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl     0.9906    0.9906    0.9906       213\n",
      "        fair     0.4640    0.5446    0.5011       213\n",
      "         gpt     0.9860    0.9953    0.9907       213\n",
      "        gpt2     0.4906    0.4860    0.4883       214\n",
      "        gpt3     0.5015    0.7840    0.6117       213\n",
      "      grover     0.6439    0.6168    0.6301       214\n",
      "       human     0.9429    0.6168    0.7458       214\n",
      " instructgpt     0.7081    0.6150    0.6583       213\n",
      "        pplm     0.8036    0.6338    0.7087       213\n",
      "         xlm     1.0000    1.0000    1.0000       213\n",
      "       xlnet     0.9906    0.9859    0.9882       213\n",
      "\n",
      "    accuracy                         0.7515      2346\n",
      "   macro avg     0.7747    0.7517    0.7558      2346\n",
      "weighted avg     0.7746    0.7515    0.7556      2346\n",
      "\n",
      "confusion matrix:  [0.99061033 0.54460094 0.99530516 0.48598131 0.78403756 0.61682243\n",
      " 0.61682243 0.61502347 0.63380282 1.         0.98591549]\n",
      "Accuracy: 0.7514919011082694\n",
      "Recall:  0.7517201766247442\n",
      "Precision:  0.7747026850727887\n",
      "F1: 0.7557592227281169\n"
     ]
    }
   ],
   "source": [
    "rd, v = classify(df['Generation'], df['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe8fbed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26d6d72c",
   "metadata": {},
   "source": [
    "## Logistic Regression multi class with TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6dc12380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data, label):\n",
    "            \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size = 0.2, random_state = 1234)\n",
    "    \n",
    "#     clf = RandomForestClassifier(random_state=1234,n_estimators=150,n_jobs=-1)\n",
    "    clf = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "#     clf = LogisticRegression(solver = 'lbfgs',multi_class='auto')\n",
    "    \n",
    "    v = TfidfVectorizer()\n",
    "    \n",
    "    train_corpus = X_train\n",
    "#     train_corpus = [[word.lower() for word in text.split()] for text in data]\n",
    "\n",
    "    test_corpus = X_test\n",
    "#     test_corpus = [\" \".join(x) for x in test_corpus]\n",
    "\n",
    "#     ax = axes.set_ylim([0,300])\n",
    "    train_vector = v.fit_transform(train_corpus)\n",
    "    test_vector = v.transform(test_corpus)\n",
    "    \n",
    "    fit = clf.fit(train_vector,y_train)\n",
    "    pred = clf.predict(test_vector)\n",
    "    \n",
    "#     # Instantiate the classification model and visualizer\n",
    "#     visualizer = ClassPredictionError(clf, classes= ['human', 'ctrl', 'gpt', 'gpt2', 'grover', 'xlm', 'xlnet', 'pplm', 'fair'])\n",
    "\n",
    "#     # Fit the training data to the visualizer\n",
    "#     visualizer.fit(train_vector, y_train)\n",
    "\n",
    "#     # Evaluate the model on the test data\n",
    "#     visualizer.score(test_vector, y_test)\n",
    "\n",
    "#     # Draw visualization\n",
    "#     visualizer.show()\n",
    "    \n",
    "    l=['ctrl','fair' ,'gpt', 'gpt2', 'gpt3', 'grover', 'human', 'instructgpt', 'pplm', 'xlm', 'xlnet']\n",
    "    matrix = confusion_matrix(y_test, pred, labels = l)\n",
    "    mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    print(classification_report(y_test, pred, labels = l,\n",
    "                                digits=4))\n",
    "    print('confusion matrix: ', mat)\n",
    "    \n",
    "    Accuracy = accuracy_score(y_test,pred)\n",
    "    F1 = f1_score(y_test, pred, average='macro')\n",
    "    print(\"Accuracy:\", Accuracy)\n",
    "    \n",
    "    rec = recall_score(y_test, pred, average='macro')\n",
    "    print('Recall: ', rec)\n",
    "    prec = precision_score(y_test, pred, average='macro')\n",
    "    print('Precision: ', prec)\n",
    "    \n",
    "    print('F1:', F1)\n",
    "    \n",
    "    return clf, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6a6515f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl     1.0000    0.9953    0.9976       213\n",
      "        fair     0.5660    0.5634    0.5647       213\n",
      "         gpt     0.9726    1.0000    0.9861       213\n",
      "        gpt2     0.5194    0.5000    0.5095       214\n",
      "        gpt3     0.4783    0.5681    0.5193       213\n",
      "      grover     0.5673    0.6495    0.6057       214\n",
      "       human     0.6905    0.5421    0.6073       214\n",
      " instructgpt     0.6367    0.7324    0.6812       213\n",
      "        pplm     0.8773    0.6714    0.7606       213\n",
      "         xlm     0.9861    1.0000    0.9930       213\n",
      "       xlnet     1.0000    0.9718    0.9857       213\n",
      "\n",
      "    accuracy                         0.7447      2346\n",
      "   macro avg     0.7540    0.7449    0.7464      2346\n",
      "weighted avg     0.7538    0.7447    0.7462      2346\n",
      "\n",
      "confusion matrix:  [0.99530516 0.56338028 1.         0.5        0.56807512 0.64953271\n",
      " 0.54205607 0.73239437 0.6713615  1.         0.97183099]\n",
      "Accuracy: 0.7446717817561808\n",
      "Recall:  0.7449032911715551\n",
      "Precision:  0.7540262153277957\n",
      "F1: 0.746443434681726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\girid\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr, v = classify(df['Generation'], df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab62f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac12014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "834be81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "be3e0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data, label):\n",
    "            \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size = 0.2, random_state = 1234)\n",
    "    \n",
    "#     clf = RandomForestClassifier(random_state=1234,n_estimators=150,n_jobs=-1)\n",
    "    clf = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "\n",
    "    v = TfidfVectorizer()\n",
    "    \n",
    "    train_corpus = X_train\n",
    "#     train_corpus = [[word.lower() for word in text.split()] for text in data]\n",
    "\n",
    "    test_corpus = X_test\n",
    "#     test_corpus = [\" \".join(x) for x in test_corpus]\n",
    "\n",
    "#     ax = axes.set_ylim([0,300])\n",
    "    train_vector = v.fit_transform(train_corpus)\n",
    "    test_vector = v.transform(test_corpus)\n",
    "    \n",
    "    fit = clf.fit(train_vector,y_train)\n",
    "    pred = clf.predict(test_vector)\n",
    "    \n",
    "#     # Instantiate the classification model and visualizer\n",
    "#     visualizer = ClassPredictionError(clf, classes= ['human', 'ctrl', 'gpt', 'gpt2', 'grover', 'xlm', 'xlnet', 'pplm', 'fair'])\n",
    "\n",
    "#     # Fit the training data to the visualizer\n",
    "#     visualizer.fit(train_vector, y_train)\n",
    "\n",
    "#     # Evaluate the model on the test data\n",
    "#     visualizer.score(test_vector, y_test)\n",
    "\n",
    "#     # Draw visualization\n",
    "#     visualizer.show()\n",
    "    \n",
    "    l=['ctrl','fair' ,'gpt', 'gpt2', 'gpt3', 'grover', 'human', 'instructgpt', 'pplm', 'xlm', 'xlnet']\n",
    "    matrix = confusion_matrix(y_test, pred, labels = l)\n",
    "    mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    print(classification_report(y_test, pred, labels = l,\n",
    "                                digits=4))\n",
    "    print('confusion matrix: ', mat)\n",
    "    \n",
    "    Accuracy = accuracy_score(y_test,pred)\n",
    "    F1 = f1_score(y_test, pred, average='macro')\n",
    "    print(\"Accuracy:\", Accuracy)\n",
    "    \n",
    "    rec = recall_score(y_test, pred, average='macro')\n",
    "    print('Recall: ', rec)\n",
    "    prec = precision_score(y_test, pred, average='macro')\n",
    "    print('Precision: ', prec)\n",
    "    \n",
    "    print('F1:', F1)\n",
    "    \n",
    "    return clf, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3018e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl     1.0000    0.9953    0.9976       213\n",
      "        fair     0.5425    0.6291    0.5826       213\n",
      "         gpt     1.0000    1.0000    1.0000       213\n",
      "        gpt2     0.5668    0.4953    0.5287       214\n",
      "        gpt3     0.4873    0.6291    0.5492       213\n",
      "      grover     0.6043    0.6636    0.6325       214\n",
      "       human     0.7257    0.5935    0.6530       214\n",
      " instructgpt     0.6952    0.6854    0.6903       213\n",
      "        pplm     0.9212    0.7136    0.8042       213\n",
      "         xlm     0.9907    1.0000    0.9953       213\n",
      "       xlnet     0.9953    0.9906    0.9929       213\n",
      "\n",
      "    accuracy                         0.7630      2346\n",
      "   macro avg     0.7754    0.7632    0.7660      2346\n",
      "weighted avg     0.7752    0.7630    0.7658      2346\n",
      "\n",
      "confusion matrix:  [0.99530516 0.62910798 1.         0.4953271  0.62910798 0.6635514\n",
      " 0.59345794 0.68544601 0.71361502 1.         0.99061033]\n",
      "Accuracy: 0.763000852514919\n",
      "Recall:  0.7632299033510037\n",
      "Precision:  0.7753662075560256\n",
      "F1: 0.7660359818802722\n"
     ]
    }
   ],
   "source": [
    "lr, v = classify(df['Generation'], df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e8837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ba801a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\girid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "19284e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "X1 = []\n",
    "\n",
    "for text in df['Generation']:\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = [[word,tag] for word, tag in pos_tag(tokens)]\n",
    "    pos_features = {word:tag for [word,tag] in pos_tags}\n",
    "    X1.append(pos_features)\n",
    "#     y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f71c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JJ': 1,\n",
       " 'NNP': 1,\n",
       " 'VB': 1,\n",
       " 'DT': 1,\n",
       " 'NN': 1,\n",
       " 'WDT': 1,\n",
       " 'VBZ': 1,\n",
       " 'TO': 1,\n",
       " 'PRP': 1}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cc1805e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Local': 'JJ',\n",
       " 'News': 'NNP',\n",
       " 'get': 'VB',\n",
       " 'the': 'DT',\n",
       " 'news': 'NN',\n",
       " 'that': 'WDT',\n",
       " \"'s\": 'VBZ',\n",
       " 'local': 'JJ',\n",
       " 'to': 'TO',\n",
       " 'you': 'PRP'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "09b08c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_the_text(data):\n",
    "    clean_data = []\n",
    "    for i in list(data['Generation']):\n",
    "        # Replace all the specified patterns with spaces\n",
    "        text = re.sub('[^A-Za-z0-9]+|<unk>|\\n| \\ |<UNK>|News|<eos>|<eod>|<eop>', ' ', str(i))\n",
    "        # Replace consecutive whitespaces with a single space\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        # Remove leading/trailing whitespaces\n",
    "        text = text.strip()\n",
    "        clean_data.append(text)\n",
    "    \n",
    "    # Create a new DataFrame with cleaned texts and original labels\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b45206d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "def get_pos(data):\n",
    "    pos = []\n",
    "    for i in data:\n",
    "        pos.append( nltk.pos_tag(word_tokenize(i)))\n",
    "    return pos\n",
    "# clean_the_text\n",
    "\n",
    "pos1 = get_pos(clean_the_text(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8e3e04bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Local', 'JJ'),\n",
       " ('News', 'NNP'),\n",
       " ('get', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('news', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('local', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('you', 'PRP')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "36a2bd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Local', 'JJ'),\n",
       " ('get', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('news', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('s', 'VBZ'),\n",
       " ('local', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('you', 'PRP')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "58fbd5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\girid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0e7388eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pos = []\n",
    "for i in pos:\n",
    "    words = nltk.FreqDist(tag for (word, tag) in i)\n",
    "    check_pos.append(list(words.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "952e19c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JJ', 'NNP', 'VB', 'DT', 'NN', 'WDT', 'VBZ', 'TO', 'PRP']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_pos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "61350653",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = [\" \".join(x) for x in check_pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d526c7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11726"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b4fabd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.DataFrame({'POS': POS, 'class': df['label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d22e441a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JJ NNP VB DT NN WDT VBZ TO PRP</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>: DT NN IN JJ NNS RB VBZ VBN CD . NNP , WRB VB...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RB NNP WRB JJ NNS VBD PRP$ NN IN CC DT , MD VB...</td>\n",
       "      <td>pplm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VBZ PRP , DT NN CC . WRB TO VB IN `` VBD JJ : ...</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VBP RB VB DT NN ( PRP MD VBG PRP$ NNS ) : NNP ...</td>\n",
       "      <td>xlm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 POS        class\n",
       "0                     JJ NNP VB DT NN WDT VBZ TO PRP        human\n",
       "1  : DT NN IN JJ NNS RB VBZ VBN CD . NNP , WRB VB...  instructgpt\n",
       "2  RB NNP WRB JJ NNS VBD PRP$ NN IN CC DT , MD VB...         pplm\n",
       "3  VBZ PRP , DT NN CC . WRB TO VB IN `` VBD JJ : ...          gpt\n",
       "4  VBP RB VB DT NN ( PRP MD VBG PRP$ NNS ) : NNP ...          xlm"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f82b8d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl     0.4538    0.5540    0.4989       213\n",
      "        fair     0.3699    0.3005    0.3316       213\n",
      "         gpt     0.6770    0.7183    0.6970       213\n",
      "        gpt2     0.4732    0.4953    0.4840       214\n",
      "        gpt3     0.5263    0.3756    0.4384       213\n",
      "      grover     0.2717    0.3505    0.3061       214\n",
      "       human     0.1915    0.1262    0.1521       214\n",
      " instructgpt     0.4803    0.6291    0.5447       213\n",
      "        pplm     0.3301    0.3192    0.3246       213\n",
      "         xlm     0.7258    0.6338    0.6767       213\n",
      "       xlnet     0.6099    0.6385    0.6239       213\n",
      "\n",
      "    accuracy                         0.4672      2346\n",
      "   macro avg     0.4645    0.4674    0.4616      2346\n",
      "weighted avg     0.4643    0.4672    0.4615      2346\n",
      "\n",
      "confusion matrix:  [0.55399061 0.30046948 0.71830986 0.4953271  0.37558685 0.35046729\n",
      " 0.12616822 0.62910798 0.31924883 0.63380282 0.63849765]\n",
      "Accuracy: 0.46717817561807334\n",
      "Recall:  0.46736151830267936\n",
      "Precision:  0.46450852875819276\n",
      "F1: 0.4616400127442274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def classify(data, label):\n",
    "            \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size = 0.2, random_state = 1234)\n",
    "    \n",
    "#     clf = RandomForestClassifier(random_state=1234,n_estimators=150,n_jobs=-1)\n",
    "    clf = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "\n",
    "    v = TfidfVectorizer()\n",
    "    \n",
    "    train_corpus = X_train\n",
    "#     train_corpus = [[word.lower() for word in text.split()] for text in data]\n",
    "\n",
    "    test_corpus = X_test\n",
    "    \n",
    "    train_vector = v.fit_transform(train_corpus)\n",
    "    test_vector = v.transform(test_corpus)\n",
    "    \n",
    "    fit = clf.fit(train_vector,y_train)\n",
    "    pred = clf.predict(test_vector)\n",
    "    \n",
    "    l=['ctrl','fair' ,'gpt', 'gpt2', 'gpt3', 'grover', 'human', 'instructgpt', 'pplm', 'xlm', 'xlnet']\n",
    "    matrix = confusion_matrix(y_test, pred, labels = l)\n",
    "    mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    print(classification_report(y_test, pred, labels = l,\n",
    "                                digits=4))\n",
    "    print('confusion matrix: ', mat)\n",
    "    \n",
    "    Accuracy = accuracy_score(y_test,pred)\n",
    "    F1 = f1_score(y_test, pred, average='macro')\n",
    "    print(\"Accuracy:\", Accuracy)\n",
    "    \n",
    "    rec = recall_score(y_test, pred, average='macro')\n",
    "    print('Recall: ', rec)\n",
    "    prec = precision_score(y_test, pred, average='macro')\n",
    "    print('Precision: ', prec)\n",
    "    \n",
    "    print('F1:', F1)\n",
    "    \n",
    "    return clf, v\n",
    "\n",
    "lr, v = classify(pos_df['POS'], pos_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9b7ac145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl     0.4570    0.5493    0.4989       213\n",
      "        fair     0.2983    0.2535    0.2741       213\n",
      "         gpt     0.6026    0.6620    0.6309       213\n",
      "        gpt2     0.4395    0.4579    0.4485       214\n",
      "        gpt3     0.4932    0.5117    0.5023       213\n",
      "      grover     0.2959    0.2336    0.2611       214\n",
      "       human     0.3964    0.3131    0.3499       214\n",
      " instructgpt     0.4894    0.5399    0.5134       213\n",
      "        pplm     0.3486    0.3568    0.3527       213\n",
      "         xlm     0.6385    0.6385    0.6385       213\n",
      "       xlnet     0.5727    0.6103    0.5909       213\n",
      "\n",
      "    accuracy                         0.4659      2346\n",
      "   macro avg     0.4575    0.4661    0.4601      2346\n",
      "weighted avg     0.4574    0.4659    0.4600      2346\n",
      "\n",
      "confusion matrix:  [0.54929577 0.25352113 0.66197183 0.45794393 0.51173709 0.23364486\n",
      " 0.31308411 0.5399061  0.35680751 0.63849765 0.61032864]\n",
      "Accuracy: 0.4658994032395567\n",
      "Recall:  0.46606714771779933\n",
      "Precision:  0.45746277927182\n",
      "F1: 0.4601062422797808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def classify(data, label):\n",
    "            \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size = 0.2, random_state = 1234)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=1234,n_estimators=150,n_jobs=-1)\n",
    "#     clf = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "\n",
    "    v = TfidfVectorizer()\n",
    "    \n",
    "    train_corpus = X_train\n",
    "#     train_corpus = [[word.lower() for word in text.split()] for text in data]\n",
    "\n",
    "    test_corpus = X_test\n",
    "    \n",
    "    train_vector = v.fit_transform(train_corpus)\n",
    "    test_vector = v.transform(test_corpus)\n",
    "    \n",
    "    fit = clf.fit(train_vector,y_train)\n",
    "    pred = clf.predict(test_vector)\n",
    "    \n",
    "    l=['ctrl','fair' ,'gpt', 'gpt2', 'gpt3', 'grover', 'human', 'instructgpt', 'pplm', 'xlm', 'xlnet']\n",
    "    matrix = confusion_matrix(y_test, pred, labels = l)\n",
    "    mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    print(classification_report(y_test, pred, labels = l,\n",
    "                                digits=4))\n",
    "    print('confusion matrix: ', mat)\n",
    "    \n",
    "    Accuracy = accuracy_score(y_test,pred)\n",
    "    F1 = f1_score(y_test, pred, average='macro')\n",
    "    print(\"Accuracy:\", Accuracy)\n",
    "    \n",
    "    rec = recall_score(y_test, pred, average='macro')\n",
    "    print('Recall: ', rec)\n",
    "    prec = precision_score(y_test, pred, average='macro')\n",
    "    print('Precision: ', prec)\n",
    "    \n",
    "    print('F1:', F1)\n",
    "    \n",
    "    return clf, v\n",
    "\n",
    "lr, v = classify(pos_df['POS'], pos_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb90afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
