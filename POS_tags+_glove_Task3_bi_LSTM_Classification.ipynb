{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganeshred/NLPAuthorshipAttributionNLM/blob/main/POS_tags%2B_glove_Task3_bi_LSTM_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpl2phjkfSKG",
        "outputId": "cf14e27d-8b3a-48e9-b5eb-4aacf370fa21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gylVe3ozfUAh",
        "outputId": "745bcac3-1976-42b5-d2a3-e672396d4692"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ze-cAYbYfWQJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/Task3 (2).csv')"
      ],
      "metadata": {
        "id": "vqjTSmsvfbRD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "jrNehKW1f0MH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "840d1c11-00d3-4898-c962-5630036dbf72"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Generation        label  label_int\n",
              "0  Flint man facing 10 dog fighting and drug deal...       grover          5\n",
              "1  the 30 most troubling lines from donald trump ...         ctrl          0\n",
              "2  Wakayama rafting is a type of traditional raft...  instructgpt          7\n",
              "3  The movies that predicted an outbreak like cor...       grover          5\n",
              "4  companies that pay taxes are allowed to use ta...         pplm          8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfc79b91-fd68-4614-8715-4b449c8a8c03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Generation</th>\n",
              "      <th>label</th>\n",
              "      <th>label_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Flint man facing 10 dog fighting and drug deal...</td>\n",
              "      <td>grover</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 30 most troubling lines from donald trump ...</td>\n",
              "      <td>ctrl</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wakayama rafting is a type of traditional raft...</td>\n",
              "      <td>instructgpt</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The movies that predicted an outbreak like cor...</td>\n",
              "      <td>grover</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>companies that pay taxes are allowed to use ta...</td>\n",
              "      <td>pplm</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfc79b91-fd68-4614-8715-4b449c8a8c03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dfc79b91-fd68-4614-8715-4b449c8a8c03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dfc79b91-fd68-4614-8715-4b449c8a8c03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Example texts\n",
        "texts = df['Generation']\n",
        "\n",
        "# Example labels\n",
        "labels = df['label']\n",
        "\n"
      ],
      "metadata": {
        "id": "M4yOfdxgfeNn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load GloVe vectors\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# Un comment this code to download glove 50d vector txt file\n",
        "# import os\n",
        "# import urllib.request\n",
        "\n",
        "# # Set the URL and file paths\n",
        "# url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "# file_path = './glove.6B.zip'\n",
        "# extract_path = '/content/gdrive/MyDrive/NLP/glove.6B'\n",
        "\n",
        "# # Download the file\n",
        "# if not os.path.exists(file_path):\n",
        "#     urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "# # Extract the file\n",
        "# if not os.path.exists(extract_path):\n",
        "#     os.makedirs(extract_path)\n",
        "#     os.system(f'unzip {file_path} -d {extract_path}')\n",
        "\n"
      ],
      "metadata": {
        "id": "GHAOA9zOCwQZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the embeddings into a dictionary\n",
        "import os\n",
        "embeddings_dict = {}\n",
        "with open(os.path.join('/content/gdrive/MyDrive/NLP/glove.6B/glove.6B.50d.txt'), 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_dict[word] = vector"
      ],
      "metadata": {
        "id": "OfTcQatl1guU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create vocabulary and index-to-token mappings for GloVe words\n",
        "glove_vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "glove_vectors_list = [np.zeros(50), np.random.normal(scale=0.6, size=50)]\n",
        "# print(glove_vectors_list)\n",
        "for word in embeddings_dict:\n",
        "    glove_vocab[word] = len(glove_vocab)\n",
        "    glove_vectors_list.append(embeddings_dict[word])\n",
        "glove_vectors_tensor = torch.FloatTensor(glove_vectors_list)\n"
      ],
      "metadata": {
        "id": "1S3ZNXwm0stL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1a832e-6f1a-49a0-f498-3602f8b3a776"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-9496caace8fa>:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  glove_vectors_tensor = torch.FloatTensor(glove_vectors_list)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pEVFLKM07Y5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vocab['the']"
      ],
      "metadata": {
        "id": "gjG7R9K607bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c431fe2-2b93-4459-e0d8-79bcb280265d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w81ZqUDM07eT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gfhSiYsx07hH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors_tensor.size()"
      ],
      "metadata": {
        "id": "KxaCKjQjCwWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd1c02a-8e6c-446b-86f0-e554bda7683a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400002, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors_tensor[3]"
      ],
      "metadata": {
        "id": "CAHtv9P_CwcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9552b507-6156-4353-a0b5-87bdc571d97a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0134,  0.2368, -0.1690,  0.4095,  0.6381,  0.4771, -0.4285, -0.5564,\n",
              "        -0.3640, -0.2394,  0.1300, -0.0637, -0.3957, -0.4816,  0.2329,  0.0902,\n",
              "        -0.1332,  0.0786, -0.4163, -0.1543,  0.1007,  0.4889,  0.3123, -0.1252,\n",
              "        -0.0375, -1.5179,  0.1261, -0.0244, -0.0430, -0.2835,  3.5416, -0.1196,\n",
              "        -0.0145, -0.1499,  0.2186, -0.3341, -0.1387,  0.3181,  0.7036,  0.4486,\n",
              "        -0.0803,  0.6300,  0.3211, -0.4676,  0.2279,  0.3603, -0.3782, -0.5666,\n",
              "         0.0447,  0.3039])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RNbT1AgtCwhu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iIwo-gj-Cwnj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "orBrbhWqgAr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c25915-c8de-428d-8271-b8249029a32e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "pos_tagged_texts = []\n",
        "for i in range(len(texts)):\n",
        "    text = texts[i]\n",
        "    label = labels[i]\n",
        "    if text is not None and not isinstance(text, float): # make sure text is not None or NaN\n",
        "      tokens = word_tokenize(text)\n",
        "      pos_tags = nltk.pos_tag(tokens)\n",
        "      pos_tagged_text = [(word, pos) for (word, pos) in pos_tags]\n",
        "      pos_tagged_texts.append((pos_tagged_text, tokens, label))\n"
      ],
      "metadata": {
        "id": "EYvnhsZsfzGL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in pos_tagged_texts[0]:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "3G0qxnJcgg2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35b1e67-e0b8-4735-cbe4-0622e3dcc92d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Flint', 'NNP'), ('man', 'NN'), ('facing', 'VBG'), ('10', 'CD'), ('dog', 'NN'), ('fighting', 'NN'), ('and', 'CC'), ('drug', 'NN'), ('dealing', 'NN'), ('charges', 'NNS'), ('flint', 'VBP'), ('mi', 'VB'), ('a', 'DT'), ('flint', 'NN'), ('man', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('arrested', 'VBN'), ('and', 'CC'), ('charged', 'VBN'), ('with', 'IN'), ('possession', 'NN'), ('of', 'IN'), ('cocaine', 'JJ'), ('drug', 'NN'), ('dealing', 'NN'), ('and', 'CC'), ('possession', 'NN'), ('of', 'IN'), ('methamphetamine', 'NN'), ('in', 'IN'), ('connection', 'NN'), ('with', 'IN'), ('a', 'DT'), ('drug', 'NN'), ('den', 'NN'), ('where', 'WRB'), ('he', 'PRP'), ('allegedly', 'RB'), ('shot', 'VBD'), ('one', 'CD'), ('or', 'CC'), ('more', 'JJR'), ('dogs', 'NNS'), ('authorities', 'NNS'), ('said', 'VBD'), ('daniel', 'JJ'), ('holtz', 'NN'), ('47', 'CD'), ('appeared', 'VBD'), ('in', 'IN'), ('the', 'DT'), ('flint', 'NN'), ('district', 'NN'), ('court', 'NN'), ('thursday', 'NN'), ('april', 'VBD'), ('4', 'CD'), ('where', 'WRB'), ('he', 'PRP'), ('was', 'VBD'), ('given', 'VBN'), ('a', 'DT'), ('statutory', 'JJ'), ('release', 'NN'), ('and', 'CC'), ('told', 'VBD'), ('he', 'PRP'), ('needs', 'VBZ'), ('to', 'TO'), ('serve', 'VB'), ('five', 'CD'), ('years', 'NNS'), ('of', 'IN'), ('probation', 'NN'), ('he', 'PRP'), ('was', 'VBD'), ('released', 'VBN'), ('tuesday', 'JJ'), ('holtz', 'NN'), ('is', 'VBZ'), ('accused', 'VBN'), ('of', 'IN'), ('grabbing', 'VBG'), ('and', 'CC'), ('handling', 'VBG'), ('pepper', 'NN'), ('spray', 'NN'), ('and', 'CC'), ('using', 'VBG'), ('it', 'PRP'), ('on', 'IN'), ('one', 'CD'), ('of', 'IN'), ('his', 'PRP$'), ('dogs', 'NNS'), ('at', 'IN'), ('a', 'DT'), ('flint', 'JJ'), ('residence', 'NN'), ('on', 'IN'), ('thursday', 'NN'), ('night', 'NN'), ('according', 'VBG'), ('to', 'TO'), ('authorities', 'NNS'), ('he', 'PRP'), ('allegedly', 'RB'), ('is', 'VBZ'), ('also', 'RB'), ('accused', 'VBN'), ('of', 'IN'), ('possessing', 'VBG'), ('two', 'CD'), ('dogs', 'NNS'), ('shot', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('head', 'NN'), ('holtz', 'NN'), ('was', 'VBD'), ('taken', 'VBN'), ('into', 'IN'), ('custody', 'NN'), ('by', 'IN'), ('flint', 'JJ'), ('police', 'NNS'), ('and', 'CC'), ('then', 'RB'), ('passed', 'VBD'), ('through', 'IN'), ('a', 'DT'), ('civilian', 'JJ'), ('transportation', 'NN'), ('car', 'NN'), ('stop', 'NN'), ('with', 'IN'), ('his', 'PRP$'), ('hands', 'NNS'), ('handcuffed', 'VBN'), ('behind', 'IN'), ('his', 'PRP$'), ('back', 'RB'), ('according', 'VBG'), ('to', 'TO'), ('police', 'NN'), ('water', 'NN'), ('main', 'JJ'), ('break', 'NN'), ('police', 'NNS'), ('say', 'VBP'), ('flint', 'NN'), ('house', 'NN'), ('in', 'IN'), ('back', 'NN'), ('of', 'IN'), ('water', 'NN'), ('main', 'JJ'), ('breaks', 'NNS'), ('sw', 'VBP'), ('getting', 'VBG'), ('out', 'IN'), ('of', 'IN'), ('the', 'DT'), ('kitchen', 'NN'), ('moms', 'NNS'), ('take', 'VBP'), ('out', 'RP'), ('their', 'PRP$'), ('plastic', 'JJ'), ('umbrella', 'NN'), ('to', 'TO'), ('protect', 'VB'), ('one', 'CD'), ('pet', 'NN'), ('from', 'IN'), ('water', 'NN'), ('main', 'JJ'), ('break', 'NN'), ('police', 'NN'), ('flint', 'NN'), ('house', 'NN'), ('in', 'IN'), ('back', 'NN'), ('of', 'IN'), ('water', 'NN'), ('main', 'JJ'), ('breaks', 'NNS'), ('sw', 'VBP'), ('getting', 'VBG'), ('out', 'IN'), ('of', 'IN'), ('the', 'DT'), ('kitchen', 'NN'), ('moms', 'NNS'), ('take', 'VBP'), ('out', 'RP'), ('their', 'PRP$'), ('plastic', 'JJ'), ('umbrella', 'NN'), ('to', 'TO'), ('protect', 'VB'), ('one', 'CD'), ('pet', 'NN'), ('from', 'IN'), ('water', 'NN'), ('main', 'JJ'), ('break', 'NN'), ('photograph', 'NN'), ('by', 'IN'), ('robyn', 'NN'), ('becker', 'NN'), ('425', 'CD'), ('w', 'NN'), ('225', 'CD'), ('w', 'NN'), ('michigan', 'NN'), ('st', 'NN'), ('photograph', 'NN'), ('by', 'IN'), ('robyn', 'NN'), ('becker', 'NN'), ('http', 'NN'), ('www', 'NN'), ('google', 'NN'), ('com', 'NN'), ('document', 'NN'), ('documents', 'NNS'), ('c', 'VBP'), ('4c38k04e6e9181x4', 'CD'), ('fam66kacw', 'JJ'), ('inifxtwc', 'NN'), ('id', 'NN'), ('u32ee5e564042d5e4fa7cbcfe7dd', 'JJ'), ('youtube', 'NN'), ('com', 'NN'), ('headge', 'NN'), ('ncbcafwk8y0zocpd', 'JJ'), ('k', 'NN'), ('id2c0jebrc5rfbcx0', 'NN'), ('c7aid10jcbjxt2cqcpihrcmd', 'NN'), ('2d2zcbjw9q9q2322b3a', 'CD'), ('agcdxe7c0', 'NN'), ('as', 'IN'), ('if', 'IN'), ('it', 'PRP'), ('were', 'VBD'), ('a', 'DT'), ('cake', 'NN'), ('but', 'CC'), ('that', 'DT'), ('s', 'VBZ'), ('not', 'RB'), ('where', 'WRB'), ('you', 'PRP'), ('see', 'VBP'), ('a', 'DT'), ('cake', 'NN'), ('a', 'DT'), ('cake', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('bakery', 'NN'), ('it', 'PRP'), ('s', 'VBZ'), ('a', 'DT'), ('motherfucker', 'NN'), ('crrrrrrrr', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('language', 'NN'), ('police', 'NN'), ('use', 'NN'), ('to', 'TO'), ('describe', 'VB'), ('dog', 'NN'), ('fighting', 'VBG'), ('in', 'IN'), ('this', 'DT'), ('case', 'NN'), ('dogs', 'NNS'), ('are', 'VBP'), ('used', 'VBN'), ('to', 'TO'), ('do', 'VB'), ('it', 'PRP'), ('but', 'CC'), ('generally', 'RB'), ('speaking', 'JJ'), ('dogs', 'NNS'), ('are', 'VBP'), ('more', 'JJR'), ('common', 'JJ'), ('in', 'IN'), ('the', 'DT'), ('streets', 'NNS'), ('than', 'IN'), ('in', 'IN'), ('dogs', 'JJ'), ('crayons', 'NNS'), ('and', 'CC'), ('dark', 'JJ'), ('toys', 'NNS'), ('etc', 'FW'), ('are', 'VBP'), ('allowed', 'VBN'), ('in', 'IN'), ('dog', 'NN'), ('fighting', 'NN'), ('in', 'IN'), ('this', 'DT'), ('case', 'NN'), ('dogs', 'NNS'), ('are', 'VBP'), ('used', 'VBN'), ('to', 'TO'), ('do', 'VB'), ('it', 'PRP'), ('but', 'CC'), ('generally', 'RB'), ('speaking', 'JJ'), ('dogs', 'NNS'), ('are', 'VBP'), ('more', 'JJR'), ('common', 'JJ'), ('in', 'IN'), ('the', 'DT'), ('streets', 'NNS'), ('than', 'IN'), ('in', 'IN'), ('dogs', 'JJ'), ('crayons', 'NNS'), ('and', 'CC'), ('dark', 'JJ'), ('toys', 'NNS'), ('etc', 'FW'), ('are', 'VBP'), ('allowed', 'VBN'), ('in', 'IN'), ('dog', 'NN'), ('fighting', 'NN'), ('in', 'IN'), ('this', 'DT'), ('case', 'NN'), ('dogs', 'NNS'), ('are', 'VBP'), ('used', 'VBN'), ('to', 'TO'), ('do', 'VB'), ('it', 'PRP'), ('but', 'CC'), ('generally', 'RB'), ('speaking', 'JJ'), ('dogs', 'NNS'), ('are', 'VBP'), ('more', 'JJR'), ('common', 'JJ'), ('in', 'IN'), ('the', 'DT'), ('streets', 'NNS'), ('than', 'IN'), ('in', 'IN'), ('dogs', 'NNS'), ('more', 'JJR'), ('pets', 'NNS'), ('fewer', 'JJR'), ('guns', 'NNS'), ('more', 'RBR'), ('kittens', 'NNS'), ('fewer', 'JJR'), ('rabbits', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('kittens', 'NNS'), ('fewer', 'JJR'), ('rabbits', 'NNS'), ('fewer', 'JJR'), ('rabbits', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('rabbits', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('rabbits', 'NNS'), ('fewer', 'JJR'), ('rabbits', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('rabbits', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS'), ('fewer', 'JJR'), ('cats', 'NNS')]\n",
            "['Flint', 'man', 'facing', '10', 'dog', 'fighting', 'and', 'drug', 'dealing', 'charges', 'flint', 'mi', 'a', 'flint', 'man', 'has', 'been', 'arrested', 'and', 'charged', 'with', 'possession', 'of', 'cocaine', 'drug', 'dealing', 'and', 'possession', 'of', 'methamphetamine', 'in', 'connection', 'with', 'a', 'drug', 'den', 'where', 'he', 'allegedly', 'shot', 'one', 'or', 'more', 'dogs', 'authorities', 'said', 'daniel', 'holtz', '47', 'appeared', 'in', 'the', 'flint', 'district', 'court', 'thursday', 'april', '4', 'where', 'he', 'was', 'given', 'a', 'statutory', 'release', 'and', 'told', 'he', 'needs', 'to', 'serve', 'five', 'years', 'of', 'probation', 'he', 'was', 'released', 'tuesday', 'holtz', 'is', 'accused', 'of', 'grabbing', 'and', 'handling', 'pepper', 'spray', 'and', 'using', 'it', 'on', 'one', 'of', 'his', 'dogs', 'at', 'a', 'flint', 'residence', 'on', 'thursday', 'night', 'according', 'to', 'authorities', 'he', 'allegedly', 'is', 'also', 'accused', 'of', 'possessing', 'two', 'dogs', 'shot', 'in', 'the', 'head', 'holtz', 'was', 'taken', 'into', 'custody', 'by', 'flint', 'police', 'and', 'then', 'passed', 'through', 'a', 'civilian', 'transportation', 'car', 'stop', 'with', 'his', 'hands', 'handcuffed', 'behind', 'his', 'back', 'according', 'to', 'police', 'water', 'main', 'break', 'police', 'say', 'flint', 'house', 'in', 'back', 'of', 'water', 'main', 'breaks', 'sw', 'getting', 'out', 'of', 'the', 'kitchen', 'moms', 'take', 'out', 'their', 'plastic', 'umbrella', 'to', 'protect', 'one', 'pet', 'from', 'water', 'main', 'break', 'police', 'flint', 'house', 'in', 'back', 'of', 'water', 'main', 'breaks', 'sw', 'getting', 'out', 'of', 'the', 'kitchen', 'moms', 'take', 'out', 'their', 'plastic', 'umbrella', 'to', 'protect', 'one', 'pet', 'from', 'water', 'main', 'break', 'photograph', 'by', 'robyn', 'becker', '425', 'w', '225', 'w', 'michigan', 'st', 'photograph', 'by', 'robyn', 'becker', 'http', 'www', 'google', 'com', 'document', 'documents', 'c', '4c38k04e6e9181x4', 'fam66kacw', 'inifxtwc', 'id', 'u32ee5e564042d5e4fa7cbcfe7dd', 'youtube', 'com', 'headge', 'ncbcafwk8y0zocpd', 'k', 'id2c0jebrc5rfbcx0', 'c7aid10jcbjxt2cqcpihrcmd', '2d2zcbjw9q9q2322b3a', 'agcdxe7c0', 'as', 'if', 'it', 'were', 'a', 'cake', 'but', 'that', 's', 'not', 'where', 'you', 'see', 'a', 'cake', 'a', 'cake', 'is', 'a', 'bakery', 'it', 's', 'a', 'motherfucker', 'crrrrrrrr', 'is', 'the', 'language', 'police', 'use', 'to', 'describe', 'dog', 'fighting', 'in', 'this', 'case', 'dogs', 'are', 'used', 'to', 'do', 'it', 'but', 'generally', 'speaking', 'dogs', 'are', 'more', 'common', 'in', 'the', 'streets', 'than', 'in', 'dogs', 'crayons', 'and', 'dark', 'toys', 'etc', 'are', 'allowed', 'in', 'dog', 'fighting', 'in', 'this', 'case', 'dogs', 'are', 'used', 'to', 'do', 'it', 'but', 'generally', 'speaking', 'dogs', 'are', 'more', 'common', 'in', 'the', 'streets', 'than', 'in', 'dogs', 'crayons', 'and', 'dark', 'toys', 'etc', 'are', 'allowed', 'in', 'dog', 'fighting', 'in', 'this', 'case', 'dogs', 'are', 'used', 'to', 'do', 'it', 'but', 'generally', 'speaking', 'dogs', 'are', 'more', 'common', 'in', 'the', 'streets', 'than', 'in', 'dogs', 'more', 'pets', 'fewer', 'guns', 'more', 'kittens', 'fewer', 'rabbits', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'kittens', 'fewer', 'rabbits', 'fewer', 'rabbits', 'fewer', 'cats', 'fewer', 'rabbits', 'fewer', 'cats', 'fewer', 'rabbits', 'fewer', 'rabbits', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'rabbits', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats', 'fewer', 'cats']\n",
            "grover\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_to_index = {pos: i for i, pos in enumerate(set([pos for text, _, label in pos_tagged_texts for word, pos in text]))}\n",
        "label_to_index = {label: i for i, label in enumerate(set([label for text, _, label in pos_tagged_texts]))}"
      ],
      "metadata": {
        "id": "lKFVyWVPidz2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_to_index"
      ],
      "metadata": {
        "id": "tzRYX49FjC44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63eab9c-33b6-4000-e5c7-aa7db9414dd2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NNS': 0,\n",
              " 'IN': 1,\n",
              " 'CD': 2,\n",
              " 'VB': 3,\n",
              " 'WDT': 4,\n",
              " 'WRB': 5,\n",
              " 'VBN': 6,\n",
              " 'RBR': 7,\n",
              " 'NNPS': 8,\n",
              " 'UH': 9,\n",
              " 'NN': 10,\n",
              " 'EX': 11,\n",
              " 'TO': 12,\n",
              " '$': 13,\n",
              " 'PRP': 14,\n",
              " ',': 15,\n",
              " 'VBZ': 16,\n",
              " '.': 17,\n",
              " \"''\": 18,\n",
              " 'MD': 19,\n",
              " 'DT': 20,\n",
              " '#': 21,\n",
              " 'JJR': 22,\n",
              " 'FW': 23,\n",
              " '``': 24,\n",
              " 'WP$': 25,\n",
              " 'RB': 26,\n",
              " 'PDT': 27,\n",
              " 'VBP': 28,\n",
              " 'JJ': 29,\n",
              " 'POS': 30,\n",
              " 'WP': 31,\n",
              " 'CC': 32,\n",
              " 'SYM': 33,\n",
              " 'RBS': 34,\n",
              " '(': 35,\n",
              " 'JJS': 36,\n",
              " 'RP': 37,\n",
              " ')': 38,\n",
              " 'NNP': 39,\n",
              " 'VBD': 40,\n",
              " ':': 41,\n",
              " 'PRP$': 42,\n",
              " 'VBG': 43}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_index"
      ],
      "metadata": {
        "id": "oQd4O5FMjEw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405f4b61-28ca-4273-a29b-ff71efd25e66"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gpt2': 0,\n",
              " 'gpt3': 1,\n",
              " 'fair': 2,\n",
              " 'xlnet': 3,\n",
              " 'gpt': 4,\n",
              " 'grover': 5,\n",
              " 'human': 6,\n",
              " 'xlm': 7,\n",
              " 'instructgpt': 8,\n",
              " 'pplm': 9,\n",
              " 'ctrl': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # print(len(batch[0]))\n",
        "    # for i in batch[0]:\n",
        "    # print(batch[0][1])\n",
        "      \n",
        "    pos_indices = [torch.tensor(sample[0], dtype=torch.long) for sample in batch]\n",
        "    pos_indices_padded = pad_sequence(pos_indices, batch_first=True, padding_value=0)\n",
        "\n",
        "    text_indices = [torch.tensor(sample[1], dtype=torch.long) for sample in batch]\n",
        "    text_indices_padded = pad_sequence(pos_indices, batch_first=True, padding_value=0)\n",
        "    \n",
        "    # for sample in batch:\n",
        "    #   for i in sample:\n",
        "    #     print(sample)\n",
        "\n",
        "    labels = torch.tensor([sample[2] for sample in batch], dtype=torch.long)\n",
        "    return pos_indices_padded,text_indices_padded, labels\n",
        "\n",
        "\n",
        "class POSTaggedTextDataset(Dataset):\n",
        "    def __init__(self, pos_tagged_texts, pos_to_index, glove_embeddings,glove_list, label_to_index):\n",
        "        self.pos_tagged_texts = pos_tagged_texts\n",
        "        self.pos_to_index = pos_to_index\n",
        "        self.glove_embeddings = glove_embeddings\n",
        "        self.glove_list = glove_list\n",
        "        self.label_to_index = label_to_index\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.pos_tagged_texts)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        postext,text, label = self.pos_tagged_texts[index]\n",
        "        \n",
        "        # Convert POS tags to indices\n",
        "        pos_indices = [self.pos_to_index[pos] for _, pos in postext]\n",
        "        \n",
        "        # Convert text to GloVe embeddings\n",
        "        # print(self.glove_embeddings[self.glove_list['word']])\n",
        "        glove_input = [self.glove_list.get(word,self.glove_list['<UNK>']) for word in text]\n",
        "        \n",
        "        # Convert label to index\n",
        "        label_index = self.label_to_index[label]\n",
        "        \n",
        "        return pos_indices, glove_input, label_index\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7OXgMbm3lLUT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_to_index = {pos: i for i, pos in enumerate(set([pos for text,_, label in pos_tagged_texts for word, pos in text]))}\n",
        "label_to_index = {label: i for i, label in enumerate(set([label for text,_, label in pos_tagged_texts]))}"
      ],
      "metadata": {
        "id": "aKtxAzn-Jd3f"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = POSTaggedTextDataset(pos_tagged_texts, pos_to_index,glove_vectors_list,glove_vocab, label_to_index)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "_f14lSLGjIOm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in dataloader:\n",
        "#   # print(len(i))\n",
        "#   for j in i:\n",
        "#     print(j.size())\n",
        "#   break"
      ],
      "metadata": {
        "id": "6YR0u52uVFeT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u_sWtZWOCKiR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_vh3qAACKfg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, prediction_text, prediction_pos, target_text):\n",
        "        # predicted_pos: (batch_size, seq_len, num_classes)\n",
        "        # target_pos: (batch_size, seq_len)\n",
        "        loss_text = F.cross_entropy(prediction_text.view(-1, prediction_text.size(-1)), target_text.view(-1))\n",
        "        \n",
        "        # Compute cross-entropy loss for POS prediction\n",
        "        loss_pos = F.cross_entropy(prediction_pos.view(-1, prediction_pos.size(-1)), target_text.view(-1))\n",
        "        \n",
        "        # Return total loss\n",
        "        total_loss = loss_text + loss_pos\n",
        "        \n",
        "        return total_loss\n",
        "\n",
        "\n",
        "# def custom_loss(prediction_text, prediction_pos, target_text):\n",
        "#     # Compute cross-entropy loss for text prediction\n",
        "#     loss_text = F.cross_entropy(prediction_text.view(-1, prediction_text.size(-1)), target_text.view(-1))\n",
        "#     # Compute cross-entropy loss for POS prediction\n",
        "#     loss_pos = F.cross_entropy(prediction_pos.view(-1, prediction_pos.size(-1)), target_text.view(-1))\n",
        "#     # Return total loss\n",
        "#     total_loss = loss_text + loss_pos\n",
        "#     return total_loss\n"
      ],
      "metadata": {
        "id": "XDlUFvwKmLfQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89GzHEfmmLkH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class POS_GloVe_LSTM(nn.Module):\n",
        "    def __init__(self, text_vocab_size, pos_vocab_size, embedding_dim, hidden_dim, num_layers, dropout, output_size):\n",
        "        super(POS_GloVe_LSTM, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        # Embedding layer for text field using GloVe embeddings\n",
        "        self.text_embedding = nn.Embedding(text_vocab_size, embedding_dim)\n",
        "        # self.text_embedding = \n",
        "        \n",
        "        # Embedding layer for POS field using default PyTorch embeddings\n",
        "        self.pos_embedding = nn.Embedding(pos_vocab_size, embedding_dim)\n",
        "        \n",
        "        # Two-layer LSTM\n",
        "        self.lstm_pos = nn.LSTM(input_size=embedding_dim, \n",
        "                            hidden_size=hidden_dim, \n",
        "                            num_layers=num_layers, \n",
        "                            dropout=dropout,bidirectional=True)\n",
        "        \n",
        "        self.lstm_text = nn.LSTM(input_size=embedding_dim, \n",
        "                            hidden_size=hidden_dim, \n",
        "                            num_layers=num_layers, \n",
        "                            dropout=dropout,bidirectional=True)\n",
        "        \n",
        "        # Linear layer to output predictions\n",
        "        self.fc = nn.Linear(2*hidden_dim, output_size)\n",
        "        \n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, pos):\n",
        "        # Embed text and POS tags\n",
        "        # x = self.embedding(text).permute(1, 0, 2)\n",
        "        text_embedded = self.text_embedding(text).permute(1, 0, 2)\n",
        "        pos_embedded = self.pos_embedding(pos).permute(1, 0, 2)\n",
        "\n",
        "        # print(text_embedded.size())\n",
        "        # print(pos_embedded.size())\n",
        "        \n",
        "        # Pass text and POS embeddings through separate LSTM layers\n",
        "        output_text, (hidden_text, cell_text) = self.lstm_text(text_embedded)\n",
        "        output_pos, (hidden_pos, cell_pos) = self.lstm_pos(pos_embedded)\n",
        "\n",
        "        # last_hidden_state = self.get_last_hidden_state(output_text)\n",
        "        # print(output_text.size())\n",
        "        # print(output_pos.size())\n",
        "\n",
        "        last_hidden_state_text = self.get_last_hidden_state(output_text)\n",
        "        last_hidden_state_pos = self.get_last_hidden_state(output_pos)\n",
        "\n",
        "        # print(last_hidden_state_text.size())\n",
        "        # print(last_hidden_state_pos.size())\n",
        "\n",
        "        \n",
        "        # # Apply dropout to LSTM output for text and POS\n",
        "        # output_text = self.dropout(output_text)\n",
        "        # output_pos = self.dropout(output_pos)\n",
        "\n",
        "        \n",
        "        \n",
        "        # Pass through linear layer\n",
        "        prediction_text = self.fc(last_hidden_state_text)\n",
        "        prediction_pos = self.fc(last_hidden_state_pos)\n",
        "        \n",
        "        return prediction_text, prediction_pos\n",
        "    def get_last_hidden_state(self, lstm_out):\n",
        "        # Extract the last hidden state of the LSTM\n",
        "        last_hidden_state_fw = lstm_out[-1, :, :self.hidden_dim]\n",
        "        last_hidden_state_bw = lstm_out[0, :, self.hidden_dim:]\n",
        "        last_hidden_state = torch.cat((last_hidden_state_fw, last_hidden_state_bw), dim=-1)\n",
        "        return last_hidden_state\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PzIM8TIiiIvK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train function\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    for pos_indices,text_indices, labels in dataloader:\n",
        "        pos_indices, labels = pos_indices.to(device), labels.to(device)\n",
        "        text_indices = text_indices.to(device)\n",
        "        # print(pos_indices.size())\n",
        "        optimizer.zero_grad()\n",
        "        outputs_text,output_pos = model(pos_indices,text_indices)\n",
        "        # print(outputs_text.size())\n",
        "        # print(output_pos.size())\n",
        "        loss = criterion(outputs_text,output_pos,labels)\n",
        "        loss_text = F.cross_entropy(outputs_text.view(-1, outputs_text.size(-1)), labels.view(-1))    \n",
        "        # Compute cross-entropy loss for POS prediction\n",
        "        loss_pos = F.cross_entropy(output_pos.view(-1, output_pos.size(-1)), labels.view(-1))\n",
        "        if (loss_text.item()<loss_pos.item()):\n",
        "            predictions = torch.argmax(outputs_text, dim=1)\n",
        "            correct_predictions += torch.sum(predictions == labels)\n",
        "            total_predictions += len(labels)\n",
        "        else:\n",
        "            predictions = torch.argmax(output_pos, dim=1)\n",
        "            correct_predictions += torch.sum(predictions == labels)\n",
        "            total_predictions += len(labels)\n",
        "\n",
        "        # loss = criterion(outputs, labels.squeeze())\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return running_loss / len(dataloader), accuracy*100\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for pos_indices, text_indices, labels in dataloader:\n",
        "            pos_indices, labels = pos_indices.to(device), labels.to(device)\n",
        "            text_indices = text_indices.to(device)\n",
        "            outputs_text, output_pos = model(pos_indices, text_indices)\n",
        "            loss = criterion(outputs_text, output_pos, labels)\n",
        "            running_loss += loss.item()\n",
        "            loss_text = F.cross_entropy(outputs_text.view(-1, outputs_text.size(-1)), labels.view(-1))    \n",
        "            # Compute cross-entropy loss for POS prediction\n",
        "            loss_pos = F.cross_entropy(output_pos.view(-1, output_pos.size(-1)), labels.view(-1))\n",
        "            if (loss_text.item()<loss_pos.item()):\n",
        "                predictions = torch.argmax(outputs_text, dim=1)\n",
        "                correct_predictions += torch.sum(predictions == labels)\n",
        "                total_predictions += len(labels)\n",
        "            else:\n",
        "                predictions = torch.argmax(output_pos, dim=1)\n",
        "                correct_predictions += torch.sum(predictions == labels)\n",
        "                total_predictions += len(labels)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return running_loss / len(dataloader), accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "juCPvc2FaUsk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vocab_size = len(glove_vocab)\n",
        "pos_vocab_size = len(pos_tags)\n",
        "embedding_dim =  50\n",
        "hidden_dim = 128\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "output_size = 11"
      ],
      "metadata": {
        "id": "qn-lmgliIcUl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = POS_GloVe_LSTM(text_vocab_size, pos_vocab_size, embedding_dim, hidden_dim, num_layers, dropout, output_size)"
      ],
      "metadata": {
        "id": "0oll4eTdaOHZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = CustomLoss()\n",
        "batch_size = 16\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders for training and validation sets\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size,collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=lambda batch: collate_fn(batch, glove_vocab, pos_to_index))\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=batch_size,collate_fn=lambda batch: collate_fn(batch, glove_vocab, pos_to_index))\n"
      ],
      "metadata": {
        "id": "uG2CkwPUJ-Rc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# num_epochs = 1\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "#     val_acc = evaluate(model, val_dataloader, criterion,device)\n",
        "#     print(\"Epoch {}/{} - Train Loss: {:.4f} - Val Acc: {:.4f}\".format(epoch+1, num_epochs, train_loss, 25))\n"
      ],
      "metadata": {
        "id": "uKb-cMr7Z1xc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=20\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = evaluate(model, val_dataloader, criterion,device)\n",
        "    print(\"Epoch {}/{} - Train Loss: {:.4f} - Train Acc: {:.4f} - Val Loss: {:.4f} - Val Acc: {:.4f}\".format(epoch+1, num_epochs, \n",
        "                                                                                                             train_loss, train_acc,\n",
        "                                                                                                       val_loss, val_acc      ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la_MA7EwZATm",
        "outputId": "cf9c7ca7-cfb8-46c8-9f8d-e904af4bb5c8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Train Loss: 1.0937 - Train Acc: 76.8829 - Val Loss: 1.0699 - Val Acc: 0.7679\n",
            "Epoch 2/20 - Train Loss: 1.0221 - Train Acc: 78.4404 - Val Loss: 1.0428 - Val Acc: 0.7773\n",
            "Epoch 3/20 - Train Loss: 0.9970 - Train Acc: 79.4965 - Val Loss: 1.0629 - Val Acc: 0.7752\n",
            "Epoch 4/20 - Train Loss: 0.9563 - Train Acc: 80.2966 - Val Loss: 0.9861 - Val Acc: 0.7820\n",
            "Epoch 5/20 - Train Loss: 0.9602 - Train Acc: 81.0113 - Val Loss: 0.9789 - Val Acc: 0.8046\n",
            "Epoch 6/20 - Train Loss: 0.9216 - Train Acc: 81.5554 - Val Loss: 1.0293 - Val Acc: 0.7974\n",
            "Epoch 7/20 - Train Loss: 0.9260 - Train Acc: 82.5795 - Val Loss: 0.9372 - Val Acc: 0.8059\n",
            "Epoch 8/20 - Train Loss: 0.8736 - Train Acc: 83.5182 - Val Loss: 0.9561 - Val Acc: 0.8093\n",
            "Epoch 9/20 - Train Loss: 0.8218 - Train Acc: 84.8730 - Val Loss: 0.9111 - Val Acc: 0.8204\n",
            "Epoch 10/20 - Train Loss: 0.7767 - Train Acc: 85.8438 - Val Loss: 0.8954 - Val Acc: 0.8221\n",
            "Epoch 11/20 - Train Loss: 0.7707 - Train Acc: 86.4839 - Val Loss: 0.9378 - Val Acc: 0.8230\n",
            "Epoch 12/20 - Train Loss: 0.7372 - Train Acc: 87.3160 - Val Loss: 0.8687 - Val Acc: 0.8328\n",
            "Epoch 13/20 - Train Loss: 0.7183 - Train Acc: 87.7214 - Val Loss: 0.8892 - Val Acc: 0.8294\n",
            "Epoch 14/20 - Train Loss: 0.7008 - Train Acc: 88.2974 - Val Loss: 0.9100 - Val Acc: 0.8298\n",
            "Epoch 15/20 - Train Loss: 0.6803 - Train Acc: 88.4254 - Val Loss: 0.9159 - Val Acc: 0.8400\n",
            "Epoch 16/20 - Train Loss: 0.6168 - Train Acc: 89.8336 - Val Loss: 0.8565 - Val Acc: 0.8554\n",
            "Epoch 17/20 - Train Loss: 0.5977 - Train Acc: 90.5803 - Val Loss: 0.9021 - Val Acc: 0.8353\n",
            "Epoch 18/20 - Train Loss: 0.5839 - Train Acc: 91.2204 - Val Loss: 0.8611 - Val Acc: 0.8545\n",
            "Epoch 19/20 - Train Loss: 0.5486 - Train Acc: 91.2097 - Val Loss: 0.8717 - Val Acc: 0.8498\n",
            "Epoch 20/20 - Train Loss: 0.5239 - Train Acc: 92.1698 - Val Loss: 0.8766 - Val Acc: 0.8528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = evaluate(model, train_dataloader, criterion,device)"
      ],
      "metadata": {
        "id": "7b0CdpPPabYX"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc"
      ],
      "metadata": {
        "id": "8DUnhdI6acGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956beae7-be54-47ac-f803-86bbb7a01151"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.45194814687295987, tensor(0.9377, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/gdrive/MyDrive/posglovemodeltask3.pt\")"
      ],
      "metadata": {
        "id": "Qa50PsX2acI-"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAFzpfTNacL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3VU2E-5acOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQO3qwuraySP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SXbmBCzUayVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TrKTRQbqayX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CnRwZqqcayaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ze_uv3F6aydn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j77cu0BXaygX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TBH7Tr4jayjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9rMICbxwaymK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TtvYIA9Fayou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HAZ6wLEqayrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HgD9FCNqacRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHqVO3P4aDY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_pos_tags = len(pos_to_index)\n",
        "# num_labels = len(label_to_index)\n",
        "# hidden_size = 128\n",
        "# num_layers = 2\n",
        "# model = POSBiLSTM(num_pos_tags, num_labels, hidden_size, num_layers,glove_vectors)\n",
        "\n",
        "# # Define the loss function and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2bLIeZZFjjhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# class POSBiLSTM(nn.Module):\n",
        "#     def __init__(self, num_pos_tags, num_labels, hidden_size, num_layers, glove_embeddings):\n",
        "#         super(POSBiLSTM, self).__init__()\n",
        "#         self.pos_embedding = nn.Embedding(num_pos_tags, hidden_size)\n",
        "#         self.glove_embeddings = glove_embeddings\n",
        "#         self.lstm = nn.LSTM(input_size=hidden_size + 50 , hidden_size=hidden_size, \n",
        "#                             num_layers=num_layers, bidirectional=True)\n",
        "#         self.fc = nn.Linear(hidden_size*2, num_labels)\n",
        "        \n",
        "#     def forward(self, pos_indices, text_indices):\n",
        "#         pos_embedded = self.pos_embedding(pos_indices).permute(1, 0, 2)  # shape: (seq_len, batch_size, hidden_size)\n",
        "#         text_embedded = self.glove_embeddings[text_indices].permute(1, 0, 2)  # shape: (seq_len, batch_size, glove_dim)\n",
        "#         x = torch.cat((pos_embedded, text_embedded), dim=-1)  # shape: (seq_len, batch_size, hidden_size + glove_dim)\n",
        "#         lstm_out, _ = self.lstm(x)  # lstm_out has shape (seq_len, batch_size, hidden_size*num_directions)\n",
        "#         last_hidden_state = self.get_last_hidden_state(lstm_out)\n",
        "#         out = self.fc(last_hidden_state)  # shape: (batch_size, num_labels)\n",
        "#         return out\n",
        "    \n",
        "#     def get_last_hidden_state(self, lstm_out):\n",
        "#         # Extract the last hidden state of the LSTM\n",
        "#         last_hidden_state_fw = lstm_out[-1, :, :self.lstm.hidden_size]\n",
        "#         last_hidden_state_bw = lstm_out[0, :, self.lstm.hidden_size:]\n",
        "#         last_hidden_state = torch.cat((last_hidden_state_fw, last_hidden_state_bw), dim=-1)\n",
        "#         return last_hidden_state\n"
      ],
      "metadata": {
        "id": "jiBVfG5njNGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train function\n",
        "# def train(model, dataloader, optimizer, criterion, device):\n",
        "#     model.train()\n",
        "#     running_loss = 0.0\n",
        "#     for pos_indices, labels in dataloader:\n",
        "#         pos_indices, labels = pos_indices.to(device), labels.to(device)\n",
        "#         # print(pos_indices.size())\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(pos_indices)\n",
        "#         # print(outputs.size())\n",
        "#         # print(labels.size())\n",
        "#         loss = criterion(outputs, labels.squeeze())\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         running_loss += loss.item()\n",
        "#     return running_loss / len(dataloader)\n",
        "\n",
        "# # Evaluate function\n",
        "# def evaluate(model, dataloader, device):\n",
        "#     model.eval()\n",
        "#     num_correct = 0\n",
        "#     num_total = 0\n",
        "#     with torch.no_grad():\n",
        "#         for pos_indices, labels in dataloader:\n",
        "#             pos_indices, labels = pos_indices.to(device), labels.to(device)\n",
        "#             outputs = model(pos_indices)\n",
        "#             _, predicted = torch.max(outputs.data, 1)\n",
        "#             num_correct += (predicted == labels.squeeze()).sum().item()\n",
        "#             num_total += pos_indices.size(0)\n",
        "#     return num_correct / num_total\n"
      ],
      "metadata": {
        "id": "M6-L9BCJjoR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Split the dataset into training and validation sets\n",
        "# train_size = int(0.8 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# # Create data loaders for training and validation sets\n",
        "# batch_size = 16\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=lambda batch: collate_fn(batch, glove_vocab, pos_to_index))\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=batch_size,collate_fn=lambda batch: collate_fn(batch, glove_vocab, pos_to_index))\n"
      ],
      "metadata": {
        "id": "5kgHH85qkuDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train the model\n",
        "# num_epochs = 1\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "# for epoch in range(num_epochs):\n",
        "#     train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "#     val_acc = evaluate(model, val_dataloader, device)\n",
        "#     print(\"Epoch {}/{} - Train Loss: {:.4f} - Val Acc: {:.4f}\".format(epoch+1, num_epochs, train_loss, val_acc))\n"
      ],
      "metadata": {
        "id": "VKEIfA5MkTdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# glove_vocab['<unk>']"
      ],
      "metadata": {
        "id": "5WISGuG3UdYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for epoch in range(num_epochs):\n",
        "#     train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "#     val_acc = evaluate(model, val_dataloader, device)\n",
        "#     print(\"Epoch {}/{} - Train Loss: {:.4f} - Val Acc: {:.4f}\".format(epoch+1, num_epochs, train_loss, val_acc))\n"
      ],
      "metadata": {
        "id": "2Xx9NDK8kxPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_acc = evaluate(model, train_dataloader, device)"
      ],
      "metadata": {
        "id": "aFF1wOFDzumw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/gdrive/MyDrive/posglovemodeltask3.pt\")\n"
      ],
      "metadata": {
        "id": "Q4AYDzoK0NiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_acc"
      ],
      "metadata": {
        "id": "swndoo0q1LZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "enQ9Hmfh1Mti"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}