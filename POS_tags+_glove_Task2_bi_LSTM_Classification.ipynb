{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganeshred/NLPAuthorshipAttributionNLM/blob/main/POS_tags%2B_glove_Task2_bi_LSTM_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpl2phjkfSKG",
        "outputId": "26dfd1b7-c16e-4397-e752-ca0df94cc75c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.1\n",
            "    Uninstalling torchtext-0.15.1:\n",
            "      Successfully uninstalled torchtext-0.15.1\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gylVe3ozfUAh",
        "outputId": "e27f30d4-301e-42c6-8d46-62e364ec15ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ze-cAYbYfWQJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/balanced_task2.csv')"
      ],
      "metadata": {
        "id": "vqjTSmsvfbRD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "jrNehKW1f0MH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2cd0c916-2659-410b-f115-497f1022ee8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                               text  class\n",
              "0         664  Netanyahu barely scratches out a victory in Is...      0\n",
              "1          61  In \"Hunters,\" the premiere episode of a new se...      0\n",
              "2         518  . cricket ice cream is a luxury ice cream made...      0\n",
              "3         248  Graciela Iturbide was born in Mexico City in 1...      0\n",
              "4         435  A new study from the University of Rochester d...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98f4da09-71da-4a24-b3a9-9fe03bb9dd9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>664</td>\n",
              "      <td>Netanyahu barely scratches out a victory in Is...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>61</td>\n",
              "      <td>In \"Hunters,\" the premiere episode of a new se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>518</td>\n",
              "      <td>. cricket ice cream is a luxury ice cream made...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>248</td>\n",
              "      <td>Graciela Iturbide was born in Mexico City in 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>435</td>\n",
              "      <td>A new study from the University of Rochester d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98f4da09-71da-4a24-b3a9-9fe03bb9dd9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98f4da09-71da-4a24-b3a9-9fe03bb9dd9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98f4da09-71da-4a24-b3a9-9fe03bb9dd9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Example texts\n",
        "texts = df['text']\n",
        "\n",
        "# Example labels\n",
        "labels = df['class']\n",
        "\n"
      ],
      "metadata": {
        "id": "M4yOfdxgfeNn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load GloVe vectors\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# Un comment this code to download glove 50d vector txt file\n",
        "# import os\n",
        "# import urllib.request\n",
        "\n",
        "# # Set the URL and file paths\n",
        "# url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "# file_path = './glove.6B.zip'\n",
        "# extract_path = '/content/gdrive/MyDrive/NLP/glove.6B'\n",
        "\n",
        "# # Download the file\n",
        "# if not os.path.exists(file_path):\n",
        "#     urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "# # Extract the file\n",
        "# if not os.path.exists(extract_path):\n",
        "#     os.makedirs(extract_path)\n",
        "#     os.system(f'unzip {file_path} -d {extract_path}')\n",
        "\n"
      ],
      "metadata": {
        "id": "GHAOA9zOCwQZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the embeddings into a dictionary\n",
        "import os\n",
        "embeddings_dict = {}\n",
        "with open(os.path.join('/content/gdrive/MyDrive/NLP/glove.6B/glove.6B.50d.txt'), 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_dict[word] = vector"
      ],
      "metadata": {
        "id": "OfTcQatl1guU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create vocabulary and index-to-token mappings for GloVe words\n",
        "glove_vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "glove_vectors_list = [np.zeros(50), np.random.normal(scale=0.6, size=50)]\n",
        "# print(glove_vectors_list)\n",
        "for word in embeddings_dict:\n",
        "    glove_vocab[word] = len(glove_vocab)\n",
        "    glove_vectors_list.append(embeddings_dict[word])\n",
        "glove_vectors_tensor = torch.FloatTensor(glove_vectors_list)\n"
      ],
      "metadata": {
        "id": "1S3ZNXwm0stL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696066d3-23d8-41a9-eebb-1af0cc5ac53e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-9496caace8fa>:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  glove_vectors_tensor = torch.FloatTensor(glove_vectors_list)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pEVFLKM07Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vocab['the']"
      ],
      "metadata": {
        "id": "gjG7R9K607bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "886213f3-5347-44e4-d105-a8d4fc743587"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w81ZqUDM07eT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gfhSiYsx07hH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors_tensor.size()"
      ],
      "metadata": {
        "id": "KxaCKjQjCwWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7042b3-6185-43c4-ceee-945652fe4492"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400002, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors_tensor[3]"
      ],
      "metadata": {
        "id": "CAHtv9P_CwcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c9050d-f2ab-4d5f-b481-946cf81200f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0134,  0.2368, -0.1690,  0.4095,  0.6381,  0.4771, -0.4285, -0.5564,\n",
              "        -0.3640, -0.2394,  0.1300, -0.0637, -0.3957, -0.4816,  0.2329,  0.0902,\n",
              "        -0.1332,  0.0786, -0.4163, -0.1543,  0.1007,  0.4889,  0.3123, -0.1252,\n",
              "        -0.0375, -1.5179,  0.1261, -0.0244, -0.0430, -0.2835,  3.5416, -0.1196,\n",
              "        -0.0145, -0.1499,  0.2186, -0.3341, -0.1387,  0.3181,  0.7036,  0.4486,\n",
              "        -0.0803,  0.6300,  0.3211, -0.4676,  0.2279,  0.3603, -0.3782, -0.5666,\n",
              "         0.0447,  0.3039])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RNbT1AgtCwhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iIwo-gj-Cwnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "orBrbhWqgAr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7975b52-f603-47db-8c0c-107abf2aecbc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "pos_tagged_texts = []\n",
        "for i in range(len(texts)):\n",
        "    text = texts[i]\n",
        "    label = labels[i]\n",
        "    if text is not None and not isinstance(text, float): # make sure text is not None or NaN\n",
        "      tokens = word_tokenize(text)\n",
        "      pos_tags = nltk.pos_tag(tokens)\n",
        "      pos_tagged_text = [(word, pos) for (word, pos) in pos_tags]\n",
        "      pos_tagged_texts.append((pos_tagged_text, tokens, label))\n"
      ],
      "metadata": {
        "id": "EYvnhsZsfzGL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in pos_tagged_texts[0]:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "3G0qxnJcgg2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98157453-38e1-4a94-fec2-d65b96c00d7e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Netanyahu', 'NNP'), ('barely', 'RB'), ('scratches', 'VBZ'), ('out', 'RP'), ('a', 'DT'), ('victory', 'NN'), ('in', 'IN'), ('Israeli', 'NNP'), ('elections', 'NNS')]\n",
            "['Netanyahu', 'barely', 'scratches', 'out', 'a', 'victory', 'in', 'Israeli', 'elections']\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_to_index = {pos: i for i, pos in enumerate(set([pos for text, _, label in pos_tagged_texts for word, pos in text]))}\n",
        "label_to_index = {label: i for i, label in enumerate(set([label for text, _, label in pos_tagged_texts]))}"
      ],
      "metadata": {
        "id": "lKFVyWVPidz2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_to_index"
      ],
      "metadata": {
        "id": "tzRYX49FjC44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d18496-ba45-45ba-bb73-8520f2e0f10c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CC': 0,\n",
              " ':': 1,\n",
              " '$': 2,\n",
              " 'WRB': 3,\n",
              " 'VBG': 4,\n",
              " 'DT': 5,\n",
              " 'PDT': 6,\n",
              " 'FW': 7,\n",
              " 'VBZ': 8,\n",
              " '#': 9,\n",
              " 'IN': 10,\n",
              " 'EX': 11,\n",
              " 'NNPS': 12,\n",
              " '(': 13,\n",
              " 'VBN': 14,\n",
              " '.': 15,\n",
              " 'VBP': 16,\n",
              " 'RBR': 17,\n",
              " 'RP': 18,\n",
              " 'RBS': 19,\n",
              " 'JJ': 20,\n",
              " 'POS': 21,\n",
              " 'RB': 22,\n",
              " 'WP': 23,\n",
              " 'PRP': 24,\n",
              " 'PRP$': 25,\n",
              " 'JJR': 26,\n",
              " ')': 27,\n",
              " ',': 28,\n",
              " 'WP$': 29,\n",
              " 'NN': 30,\n",
              " 'NNS': 31,\n",
              " 'WDT': 32,\n",
              " '``': 33,\n",
              " 'VBD': 34,\n",
              " 'MD': 35,\n",
              " 'NNP': 36,\n",
              " 'TO': 37,\n",
              " 'CD': 38,\n",
              " 'UH': 39,\n",
              " \"''\": 40,\n",
              " 'JJS': 41,\n",
              " 'SYM': 42,\n",
              " 'VB': 43}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_index"
      ],
      "metadata": {
        "id": "oQd4O5FMjEw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f1a073-5364-4e4d-e885-cc704bd836fd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 1}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # print(len(batch[0]))\n",
        "    # for i in batch[0]:\n",
        "    # print(batch[0][1])\n",
        "      \n",
        "    pos_indices = [torch.tensor(sample[0], dtype=torch.long) for sample in batch]\n",
        "    pos_indices_padded = pad_sequence(pos_indices, batch_first=True, padding_value=0)\n",
        "\n",
        "    text_indices = [torch.tensor(sample[1], dtype=torch.long) for sample in batch]\n",
        "    text_indices_padded = pad_sequence(pos_indices, batch_first=True, padding_value=0)\n",
        "    \n",
        "    # for sample in batch:\n",
        "    #   for i in sample:\n",
        "    #     print(sample)\n",
        "\n",
        "    labels = torch.tensor([sample[2] for sample in batch], dtype=torch.long)\n",
        "    return pos_indices_padded,text_indices_padded, labels\n",
        "\n",
        "\n",
        "class POSTaggedTextDataset(Dataset):\n",
        "    def __init__(self, pos_tagged_texts, pos_to_index, glove_embeddings,glove_list, label_to_index):\n",
        "        self.pos_tagged_texts = pos_tagged_texts\n",
        "        self.pos_to_index = pos_to_index\n",
        "        self.glove_embeddings = glove_embeddings\n",
        "        self.glove_list = glove_list\n",
        "        self.label_to_index = label_to_index\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.pos_tagged_texts)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        postext,text, label = self.pos_tagged_texts[index]\n",
        "        \n",
        "        # Convert POS tags to indices\n",
        "        pos_indices = [self.pos_to_index[pos] for _, pos in postext]\n",
        "        \n",
        "        # Convert text to GloVe embeddings\n",
        "        # print(self.glove_embeddings[self.glove_list['word']])\n",
        "        glove_input = [self.glove_list.get(word,self.glove_list['<UNK>']) for word in text]\n",
        "        \n",
        "        # Convert label to index\n",
        "        label_index = self.label_to_index[label]\n",
        "        \n",
        "        return pos_indices, glove_input, label_index\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7OXgMbm3lLUT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_to_index = {pos: i for i, pos in enumerate(set([pos for text,_, label in pos_tagged_texts for word, pos in text]))}\n",
        "label_to_index = {label: i for i, label in enumerate(set([label for text,_, label in pos_tagged_texts]))}"
      ],
      "metadata": {
        "id": "aKtxAzn-Jd3f"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = POSTaggedTextDataset(pos_tagged_texts, pos_to_index,glove_vectors_list,glove_vocab, label_to_index)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "_f14lSLGjIOm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in dataloader:\n",
        "#   # print(len(i))\n",
        "#   for j in i:\n",
        "#     print(j.size())\n",
        "#   break"
      ],
      "metadata": {
        "id": "6YR0u52uVFeT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u_sWtZWOCKiR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_vh3qAACKfg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, prediction_text, prediction_pos, target_text):\n",
        "        # predicted_pos: (batch_size, seq_len, num_classes)\n",
        "        # target_pos: (batch_size, seq_len)\n",
        "        loss_text = F.cross_entropy(prediction_text.view(-1, prediction_text.size(-1)), target_text.view(-1))\n",
        "        \n",
        "        # Compute cross-entropy loss for POS prediction\n",
        "        loss_pos = F.cross_entropy(prediction_pos.view(-1, prediction_pos.size(-1)), target_text.view(-1))\n",
        "        \n",
        "        # Return total loss\n",
        "        total_loss = loss_text + loss_pos\n",
        "        \n",
        "        return total_loss\n",
        "\n",
        "\n",
        "# def custom_loss(prediction_text, prediction_pos, target_text):\n",
        "#     # Compute cross-entropy loss for text prediction\n",
        "#     loss_text = F.cross_entropy(prediction_text.view(-1, prediction_text.size(-1)), target_text.view(-1))\n",
        "#     # Compute cross-entropy loss for POS prediction\n",
        "#     loss_pos = F.cross_entropy(prediction_pos.view(-1, prediction_pos.size(-1)), target_text.view(-1))\n",
        "#     # Return total loss\n",
        "#     total_loss = loss_text + loss_pos\n",
        "#     return total_loss\n"
      ],
      "metadata": {
        "id": "XDlUFvwKmLfQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89GzHEfmmLkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class POS_GloVe_LSTM(nn.Module):\n",
        "    def __init__(self, text_vocab_size, pos_vocab_size, embedding_dim, hidden_dim, num_layers, dropout, output_size):\n",
        "        super(POS_GloVe_LSTM, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        # Embedding layer for text field using GloVe embeddings\n",
        "        self.text_embedding = nn.Embedding(text_vocab_size, embedding_dim)\n",
        "        # self.text_embedding = \n",
        "        \n",
        "        # Embedding layer for POS field using default PyTorch embeddings\n",
        "        self.pos_embedding = nn.Embedding(pos_vocab_size, embedding_dim)\n",
        "        \n",
        "        # Two-layer LSTM\n",
        "        self.lstm_pos = nn.LSTM(input_size=embedding_dim, \n",
        "                            hidden_size=hidden_dim, \n",
        "                            num_layers=num_layers, \n",
        "                            dropout=dropout,bidirectional=True)\n",
        "        \n",
        "        self.lstm_text = nn.LSTM(input_size=embedding_dim, \n",
        "                            hidden_size=hidden_dim, \n",
        "                            num_layers=num_layers, \n",
        "                            dropout=dropout,bidirectional=True)\n",
        "        \n",
        "        # Linear layer to output predictions\n",
        "        self.fc = nn.Linear(2*hidden_dim, output_size)\n",
        "        \n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, pos):\n",
        "        # Embed text and POS tags\n",
        "        # x = self.embedding(text).permute(1, 0, 2)\n",
        "        text_embedded = self.text_embedding(text).permute(1, 0, 2)\n",
        "        pos_embedded = self.pos_embedding(pos).permute(1, 0, 2)\n",
        "\n",
        "        # print(text_embedded.size())\n",
        "        # print(pos_embedded.size())\n",
        "        \n",
        "        # Pass text and POS embeddings through separate LSTM layers\n",
        "        output_text, (hidden_text, cell_text) = self.lstm_text(text_embedded)\n",
        "        output_pos, (hidden_pos, cell_pos) = self.lstm_pos(pos_embedded)\n",
        "\n",
        "        # last_hidden_state = self.get_last_hidden_state(output_text)\n",
        "        # print(output_text.size())\n",
        "        # print(output_pos.size())\n",
        "\n",
        "        last_hidden_state_text = self.get_last_hidden_state(output_text)\n",
        "        last_hidden_state_pos = self.get_last_hidden_state(output_pos)\n",
        "\n",
        "        # print(last_hidden_state_text.size())\n",
        "        # print(last_hidden_state_pos.size())\n",
        "\n",
        "        \n",
        "        # # Apply dropout to LSTM output for text and POS\n",
        "        # output_text = self.dropout(output_text)\n",
        "        # output_pos = self.dropout(output_pos)\n",
        "\n",
        "        \n",
        "        \n",
        "        # Pass through linear layer\n",
        "        prediction_text = self.fc(last_hidden_state_text)\n",
        "        prediction_pos = self.fc(last_hidden_state_pos)\n",
        "        \n",
        "        return prediction_text, prediction_pos\n",
        "    def get_last_hidden_state(self, lstm_out):\n",
        "        # Extract the last hidden state of the LSTM\n",
        "        last_hidden_state_fw = lstm_out[-1, :, :self.hidden_dim]\n",
        "        last_hidden_state_bw = lstm_out[0, :, self.hidden_dim:]\n",
        "        last_hidden_state = torch.cat((last_hidden_state_fw, last_hidden_state_bw), dim=-1)\n",
        "        return last_hidden_state\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PzIM8TIiiIvK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train function\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    for pos_indices,text_indices, labels in dataloader:\n",
        "        pos_indices, labels = pos_indices.to(device), labels.to(device)\n",
        "        text_indices = text_indices.to(device)\n",
        "        # print(pos_indices.size())\n",
        "        optimizer.zero_grad()\n",
        "        outputs_text,output_pos = model(pos_indices,text_indices)\n",
        "        # print(outputs_text.size())\n",
        "        # print(output_pos.size())\n",
        "        loss = criterion(outputs_text,output_pos,labels)\n",
        "        loss_text = F.cross_entropy(outputs_text.view(-1, outputs_text.size(-1)), labels.view(-1))    \n",
        "        # Compute cross-entropy loss for POS prediction\n",
        "        loss_pos = F.cross_entropy(output_pos.view(-1, output_pos.size(-1)), labels.view(-1))\n",
        "        if (loss_text.item()<loss_pos.item()):\n",
        "            predictions = torch.argmax(outputs_text, dim=1)\n",
        "            correct_predictions += torch.sum(predictions == labels)\n",
        "            total_predictions += len(labels)\n",
        "        else:\n",
        "            predictions = torch.argmax(output_pos, dim=1)\n",
        "            correct_predictions += torch.sum(predictions == labels)\n",
        "            total_predictions += len(labels)\n",
        "\n",
        "        # loss = criterion(outputs, labels.squeeze())\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return running_loss / len(dataloader), accuracy*100\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for pos_indices, text_indices, labels in dataloader:\n",
        "            pos_indices, labels = pos_indices.to(device), labels.to(device)\n",
        "            text_indices = text_indices.to(device)\n",
        "            outputs_text, output_pos = model(pos_indices, text_indices)\n",
        "            loss = criterion(outputs_text, output_pos, labels)\n",
        "            running_loss += loss.item()\n",
        "            loss_text = F.cross_entropy(outputs_text.view(-1, outputs_text.size(-1)), labels.view(-1))    \n",
        "            # Compute cross-entropy loss for POS prediction\n",
        "            loss_pos = F.cross_entropy(output_pos.view(-1, output_pos.size(-1)), labels.view(-1))\n",
        "            if (loss_text.item()<loss_pos.item()):\n",
        "                predictions = torch.argmax(outputs_text, dim=1)\n",
        "                correct_predictions += torch.sum(predictions == labels)\n",
        "                total_predictions += len(labels)\n",
        "            else:\n",
        "                predictions = torch.argmax(output_pos, dim=1)\n",
        "                correct_predictions += torch.sum(predictions == labels)\n",
        "                total_predictions += len(labels)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return running_loss / len(dataloader), accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "juCPvc2FaUsk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vocab_size = len(glove_vocab)\n",
        "pos_vocab_size = len(pos_tags)\n",
        "embedding_dim =  50\n",
        "hidden_dim = 128\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "output_size = 2"
      ],
      "metadata": {
        "id": "qn-lmgliIcUl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = POS_GloVe_LSTM(text_vocab_size, pos_vocab_size, embedding_dim, hidden_dim, num_layers, dropout, output_size)"
      ],
      "metadata": {
        "id": "0oll4eTdaOHZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = CustomLoss()\n",
        "batch_size = 16\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders for training and validation sets\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size,collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=lambda batch: collate_fn(batch, glove_vocab, pos_to_index))\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=batch_size,collate_fn=lambda batch: collate_fn(batch, glove_vocab, pos_to_index))\n"
      ],
      "metadata": {
        "id": "uG2CkwPUJ-Rc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# num_epochs = 1\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "#     val_acc = evaluate(model, val_dataloader, criterion,device)\n",
        "#     print(\"Epoch {}/{} - Train Loss: {:.4f} - Val Acc: {:.4f}\".format(epoch+1, num_epochs, train_loss, 25))\n"
      ],
      "metadata": {
        "id": "uKb-cMr7Z1xc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=30\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = evaluate(model, val_dataloader, criterion,device)\n",
        "    print(\"Epoch {}/{} - Train Loss: {:.4f} - Train Acc: {:.4f} - Val Loss: {:.4f} - Val Acc: {:.4f}\".format(epoch+1, num_epochs, \n",
        "                                                                                                             train_loss, train_acc,\n",
        "                                                                                                       val_loss, val_acc      ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la_MA7EwZATm",
        "outputId": "ef740f9c-40ee-423d-b705-9db6557e11e5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Train Loss: 1.1503 - Train Acc: 72.6581 - Val Loss: 1.0507 - Val Acc: 0.7611\n",
            "Epoch 2/30 - Train Loss: 0.9392 - Train Acc: 81.0890 - Val Loss: 0.9326 - Val Acc: 0.8126\n",
            "Epoch 3/30 - Train Loss: 0.8044 - Train Acc: 84.8946 - Val Loss: 0.8512 - Val Acc: 0.8454\n",
            "Epoch 4/30 - Train Loss: 0.7072 - Train Acc: 86.5925 - Val Loss: 0.8092 - Val Acc: 0.8618\n",
            "Epoch 5/30 - Train Loss: 0.6153 - Train Acc: 89.4614 - Val Loss: 0.8193 - Val Acc: 0.8595\n",
            "Epoch 6/30 - Train Loss: 0.5725 - Train Acc: 90.6323 - Val Loss: 0.7652 - Val Acc: 0.8712\n",
            "Epoch 7/30 - Train Loss: 0.5127 - Train Acc: 92.5059 - Val Loss: 0.7547 - Val Acc: 0.8712\n",
            "Epoch 8/30 - Train Loss: 0.4660 - Train Acc: 93.0913 - Val Loss: 0.8503 - Val Acc: 0.8571\n",
            "Epoch 9/30 - Train Loss: 0.4138 - Train Acc: 94.4965 - Val Loss: 0.8752 - Val Acc: 0.8548\n",
            "Epoch 10/30 - Train Loss: 0.3763 - Train Acc: 95.6674 - Val Loss: 0.9261 - Val Acc: 0.8501\n",
            "Epoch 11/30 - Train Loss: 0.3343 - Train Acc: 95.8431 - Val Loss: 0.8015 - Val Acc: 0.8806\n",
            "Epoch 12/30 - Train Loss: 0.3328 - Train Acc: 96.5457 - Val Loss: 0.8989 - Val Acc: 0.8876\n",
            "Epoch 13/30 - Train Loss: 0.2732 - Train Acc: 97.3068 - Val Loss: 0.9077 - Val Acc: 0.8735\n",
            "Epoch 14/30 - Train Loss: 0.2327 - Train Acc: 97.8923 - Val Loss: 0.9316 - Val Acc: 0.8782\n",
            "Epoch 15/30 - Train Loss: 0.1972 - Train Acc: 98.2436 - Val Loss: 1.0071 - Val Acc: 0.8806\n",
            "Epoch 16/30 - Train Loss: 0.2036 - Train Acc: 98.1265 - Val Loss: 1.1114 - Val Acc: 0.8829\n",
            "Epoch 17/30 - Train Loss: 0.1939 - Train Acc: 98.4777 - Val Loss: 1.0346 - Val Acc: 0.8735\n",
            "Epoch 18/30 - Train Loss: 0.1838 - Train Acc: 98.3606 - Val Loss: 1.0910 - Val Acc: 0.8665\n",
            "Epoch 19/30 - Train Loss: 0.1951 - Train Acc: 98.8290 - Val Loss: 1.0887 - Val Acc: 0.8689\n",
            "Epoch 20/30 - Train Loss: 0.1341 - Train Acc: 98.9461 - Val Loss: 1.1529 - Val Acc: 0.8782\n",
            "Epoch 21/30 - Train Loss: 0.1121 - Train Acc: 99.0047 - Val Loss: 1.1758 - Val Acc: 0.8829\n",
            "Epoch 22/30 - Train Loss: 0.0952 - Train Acc: 99.2389 - Val Loss: 1.4256 - Val Acc: 0.8782\n",
            "Epoch 23/30 - Train Loss: 0.0836 - Train Acc: 99.2974 - Val Loss: 1.4071 - Val Acc: 0.8806\n",
            "Epoch 24/30 - Train Loss: 0.1629 - Train Acc: 98.7705 - Val Loss: 1.2041 - Val Acc: 0.8618\n",
            "Epoch 25/30 - Train Loss: 0.1776 - Train Acc: 98.5948 - Val Loss: 1.1503 - Val Acc: 0.8689\n",
            "Epoch 26/30 - Train Loss: 0.1123 - Train Acc: 99.0047 - Val Loss: 1.2310 - Val Acc: 0.8665\n",
            "Epoch 27/30 - Train Loss: 0.0827 - Train Acc: 99.1218 - Val Loss: 1.3408 - Val Acc: 0.8595\n",
            "Epoch 28/30 - Train Loss: 0.0925 - Train Acc: 99.2389 - Val Loss: 1.4185 - Val Acc: 0.8595\n",
            "Epoch 29/30 - Train Loss: 0.0879 - Train Acc: 99.4145 - Val Loss: 1.4691 - Val Acc: 0.8548\n",
            "Epoch 30/30 - Train Loss: 0.0707 - Train Acc: 99.5902 - Val Loss: 1.4172 - Val Acc: 0.8782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = evaluate(model, train_dataloader, criterion,device)"
      ],
      "metadata": {
        "id": "7b0CdpPPabYX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc"
      ],
      "metadata": {
        "id": "8DUnhdI6acGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a0b489-f618-411e-c6e1-d8621743285f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.045699734806527045, tensor(0.9959, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/gdrive/MyDrive/posglovemodeltask2.pt\")"
      ],
      "metadata": {
        "id": "Qa50PsX2acI-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAFzpfTNacL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3VU2E-5acOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQO3qwuraySP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SXbmBCzUayVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TrKTRQbqayX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CnRwZqqcayaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ze_uv3F6aydn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j77cu0BXaygX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TBH7Tr4jayjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9rMICbxwaymK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TtvYIA9Fayou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HAZ6wLEqayrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HgD9FCNqacRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHqVO3P4aDY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_pos_tags = len(pos_to_index)\n",
        "# num_labels = len(label_to_index)\n",
        "# hidden_size = 128\n",
        "# num_layers = 2\n",
        "# model = POSBiLSTM(num_pos_tags, num_labels, hidden_size, num_layers,glove_vectors)\n",
        "\n",
        "# # Define the loss function and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2bLIeZZFjjhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# class POSBiLSTM(nn.Module):\n",
        "#     def __init__(self, num_pos_tags, num_labels, hidden_size, num_layers, glove_embeddings):\n",
        "#         super(POSBiLSTM, self).__init__()\n",
        "#         self.pos_embedding = nn.Embedding(num_pos_tags, hidden_size)\n",
        "#         self.glove_embeddings = glove_embeddings\n",
        "#         self.lstm = nn.LSTM(input_size=hidden_size + 50 , hidden_size=hidden_size, \n",
        "#                             num_layers=num_layers, bidirectional=True)\n",
        "#         self.fc = nn.Linear(hidden_size*2, num_labels)\n",
        "        \n",
        "#     def forward(self, pos_indices, text_indices):\n",
        "#         pos_embedded = self.pos_embedding(pos_indices).permute(1, 0, 2)  # shape: (seq_len, batch_size, hidden_size)\n",
        "#         text_embedded = self.glove_embeddings[text_indices].permute(1, 0, 2)  # shape: (seq_len, batch_size, glove_dim)\n",
        "#         x = torch.cat((pos_embedded, text_embedded), dim=-1)  # shape: (seq_len, batch_size, hidden_size + glove_dim)\n",
        "#         lstm_out, _ = self.lstm(x)  # lstm_out has shape (seq_len, batch_size, hidden_size*num_directions)\n",
        "#         last_hidden_state = self.get_last_hidden_state(lstm_out)\n",
        "#         out = self.fc(last_hidden_state)  # shape: (batch_size, num_labels)\n",
        "#         return out\n",
        "    \n",
        "#     def get_last_hidden_state(self, lstm_out):\n",
        "#         # Extract the last hidden state of the LSTM\n",
        "#         last_hidden_state_fw = lstm_out[-1, :, :self.lstm.hidden_size]\n",
        "#         last_hidden_state_bw = lstm_out[0, :, self.lstm.hidden_size:]\n",
        "#         last_hidden_state = torch.cat((last_hidden_state_fw, last_hidden_state_bw), dim=-1)\n",
        "#         return last_hidden_state\n"
      ],
      "metadata": {
        "id": "jiBVfG5njNGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train function\n",
        "# def train(model, dataloader, optimizer, criterion, device):\n",
        "#     model.train()\n",
        "#     running_loss = 0.0\n",
        "#     for pos_indices, labels in dataloader:\n",
        "#         pos_indices, labels = pos_indices.to(device), labels.to(device)\n",
        "#         # print(pos_indices.size())\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(pos_indices)\n",
        "#         # print(outputs.size())\n",
        "#         # print(labels.size())\n",
        "#         loss = criterion(outputs, labels.squeeze())\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         running_loss += loss.item()\n",
        "#     return running_loss / len(dataloader)\n",
        "\n",
        "# # Evaluate function\n",
        "# def evaluate(model, dataloader, device):\n",
        "#     model.eval()\n",
        "#     num_correct = 0\n",
        "#     num_total = 0\n",
        "#     with torch.no_grad():\n",
        "#         for pos_indices, labels in dataloader:\n",
        "#             pos_indices, labels = pos_indices.to(device), labels.to(device)\n",
        "#             outputs = model(pos_indices)\n",
        "#             _, predicted = torch.max(outputs.data, 1)\n",
        "#             num_correct += (predicted == labels.squeeze()).sum().item()\n",
        "#             num_total += pos_indices.size(0)\n",
        "#     return num_correct / num_total\n"
      ],
      "metadata": {
        "id": "M6-L9BCJjoR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Split the dataset into training and validation sets\n",
        "# train_size = int(0.8 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# # Create data loaders for training and validation sets\n",
        "# batch_size = 16\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=lambda batch: collate_fn(batch, glove_vocab, pos_to_index))\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=batch_size,collate_fn=lambda batch: collate_fn(batch, glove_vocab, pos_to_index))\n"
      ],
      "metadata": {
        "id": "5kgHH85qkuDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train the model\n",
        "# num_epochs = 1\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "# for epoch in range(num_epochs):\n",
        "#     train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "#     val_acc = evaluate(model, val_dataloader, device)\n",
        "#     print(\"Epoch {}/{} - Train Loss: {:.4f} - Val Acc: {:.4f}\".format(epoch+1, num_epochs, train_loss, val_acc))\n"
      ],
      "metadata": {
        "id": "VKEIfA5MkTdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# glove_vocab['<unk>']"
      ],
      "metadata": {
        "id": "5WISGuG3UdYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for epoch in range(num_epochs):\n",
        "#     train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "#     val_acc = evaluate(model, val_dataloader, device)\n",
        "#     print(\"Epoch {}/{} - Train Loss: {:.4f} - Val Acc: {:.4f}\".format(epoch+1, num_epochs, train_loss, val_acc))\n"
      ],
      "metadata": {
        "id": "2Xx9NDK8kxPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_acc = evaluate(model, train_dataloader, device)"
      ],
      "metadata": {
        "id": "aFF1wOFDzumw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/gdrive/MyDrive/posglovemodeltask3.pt\")\n"
      ],
      "metadata": {
        "id": "Q4AYDzoK0NiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_acc"
      ],
      "metadata": {
        "id": "swndoo0q1LZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "enQ9Hmfh1Mti"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}