{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPS5O4d1l7Z4vp8Riiq/sEk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganeshred/NLPAuthorshipAttributionNLM/blob/main/sentence_pool_embeddings_task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G4Pj56oNRv0",
        "outputId": "a2899217-ad49-48b6-f598-960586eb8843"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
      ],
      "metadata": {
        "id": "mVdKsozD-ABs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CerFcqhYNeo5",
        "outputId": "ec29c29c-069f-43ef-f3fe-9506dc74b02e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', tokenizer_language='en_core_web_sm', include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "metadata": {
        "id": "2f31E7biNer0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "869PvF4WNeuv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('/content/gdrive/MyDrive/Task3.csv')"
      ],
      "metadata": {
        "id": "6n41G-m4Nexk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kmj6-xRwslY8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctrl_df = pd.read_csv('/content/gdrive/MyDrive/NLP/new_ctrl.csv')\n",
        "fair_df = pd.read_csv('/content/gdrive/MyDrive/NLP/new_fair.csv')\n",
        "gpt_df = pd.read_csv('/content/gdrive/MyDrive/NLP/new_gpt.csv')\n",
        "gpt2_df = pd.read_csv('/content/gdrive/MyDrive/NLP/new_gpt2.csv')\n",
        "grover_df = pd.read_csv('/content/gdrive/MyDrive/NLP/new_grover.csv')\n",
        "human_df = pd.read_csv('/content/gdrive/MyDrive/NLP/new_human.csv')\n",
        "pplm_df = pd.read_csv('/content/gdrive/MyDrive/NLP/new_pplm.csv')\n",
        "xlm_df = pd.read_csv('/content/gdrive/MyDrive/NLP/new_xlm.csv')\n",
        "xlnet_df = pd.read_csv('/content/gdrive/MyDrive/NLP/new_xlnet.csv')\n",
        "instruct_df = pd.read_csv('/content/gdrive/MyDrive/NLP/instruct.csv')\n",
        "gpt3_df = pd.read_csv('/content/gdrive/MyDrive/NLP/gpt3.csv')"
      ],
      "metadata": {
        "id": "M8ifmQe8slbw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctrl_df = ctrl_df[['Generation','label']]\n",
        "fair_df = fair_df[['Generation','label']]\n",
        "gpt_df = gpt_df[['Generation','label']]\n",
        "gpt3_df = gpt3_df[['Generation','label']]\n",
        "gpt2_df = gpt2_df[['Generation','label']]\n",
        "grover_df = grover_df[['Generation','label']]\n",
        "human_df = human_df[['Generation','label']]\n",
        "pplm_df = pplm_df[['Generation','label']]\n",
        "xlm_df = xlm_df[['Generation','label']]\n",
        "xlnet_df = xlnet_df[['Generation','label']]\n",
        "instruct_df = instruct_df[['Generation','label']]\n"
      ],
      "metadata": {
        "id": "pEVbWXJN1Q3H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctrl_df['Generation'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "KR1VmzUbn3VE",
        "outputId": "36da57ee-4f8c-4e33-ef9c-327d510ee31a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'latest headlines on cnn business tl;dr the u.s. government is expected to announce a new round of sanctions against iran next week, which could include the freezing or closing down iranian banks and other financial institutions, according to... [cartoon] -- a senior white house official said monday that president barack obama will sign an executive order this week imposing additional economic penalties aimed at pressuring tehran over its nuclear program. in addition, secretary of state hillary rodham clinton plans t...more from moneywatch \". | report as abusive, click here first published in money & business, march 26, 2009 8:28 a.m. et ============================================================ stocks tumble after report shows us economy shrinking for first time since 2008 - wall street journal http://on.wsj.com/1o6p2lh markets were lower monday, with dow jones industrial average falling more than 200 points, while treasury yields fell sharply. see full story. for international markets see www.bloomberg.com. click here to close this article [...] read morehttp://www.reuters.com/article/newsone/idusn0257342620080305?sp=true ) ( full answer )yes it does but not all companies do it. some have their own it department so they can manage everything themselves. others just use microsoft office 2007 because it\\'s free! you should check out my answer below if you want some help :-). but i am sure there are many others who don\\'t care about that. :) have fun reading your answers ^^ your question was posted by [ reddit user \\'reddit\\' ](http://www.redditor / r4katean_geek may 5, 10:29 @ 11:23:28:54, 1 2 hours ago via mobile : * if someone asked me \" why didn\\'t get fired? because he got fired? it\\'s computer guy has been working now i would be able too much better job now. he had no one thing when we need him back then his company computers work fine (just like windows 7 days ago. so why can\\'t run windows xp.. and i\\'m still works great jobs\" ~~~~ 4 years old version 6 months before she worked good luck up until now!???? how long term 5 year old. also how come on! is what happened today @gmail gmailingame xd *&ltd 3 weeks ago..s also worksry u know most likely tomorrow morning = what else 8 month my friend called ms word office pc 8+; aol mail mail.com xbox office 2010 outlook 2005 + websites where email server 2003 yahoo email --- yahoo! home page view all news'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# def get_sentence_embeddings(article):\n",
        "#     doc = nlp(article)\n",
        "#     sentence_embeddings = []\n",
        "#     for sent in doc.sents:\n",
        "#         # print(sent)\n",
        "#         # Compute the average GloVe embedding for each word in the sentence\n",
        "#         embeddings = []\n",
        "#         for word in sent:\n",
        "#           if not word.is_punct and not word.is_stop:\n",
        "#             print(nlp.vocab.get_vector(word.text.lower()))\n",
        "\n",
        "\n",
        "#     #     embeddings = [nlp.vocab.get_vector(word.text.lower()) for word in sent if not word.is_punct and not word.is_stop]\n",
        "#     #     print(embeddings)\n",
        "#     #     if embeddings:\n",
        "#     #         sentence_embeddings.append(np.mean(embeddings, axis=0))\n",
        "#     # return sentence_embeddings\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6kiKIuSn3SP",
        "outputId": "a4f80546-4c0c-4dc0-ee84-3722177d283a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load GloVe embeddings\n",
        "embeddings = {}\n",
        "with open(\"/content/gdrive/MyDrive/NLP/glove.6B.50d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = torch.tensor([float(val) for val in values[1:]])\n",
        "        embeddings[word] = vector\n",
        "\n",
        "def get_sentence_embeddings(article):\n",
        "    doc = nlp(str(article))\n",
        "    sentence_embeddings = []\n",
        "    sents = list(doc.sents)\n",
        "    for i in range(0,len(list(sents)),5):\n",
        "    # for sent in doc.sents:\n",
        "        # Compute the average GloVe embedding for each word in the sentence\n",
        "        if (i+4 <= len(list(doc.sents))-1):\n",
        "          super_sent = list(doc.sents)[i:i+5]\n",
        "          sent = ''.join(str(super_sent))\n",
        "          sent = nlp(sent)\n",
        "        else:\n",
        "          super_sent = list(doc.sents)[i]\n",
        "          sent = ''.join(str(super_sent))\n",
        "          sent = nlp(sent)\n",
        "        sent_embeddings = []\n",
        "        for word in sent:\n",
        "            if not word.is_punct and not word.is_stop:\n",
        "                embedding = embeddings.get(word.lower_, None)\n",
        "                if embedding is not None and embedding != []:\n",
        "                    sent_embeddings.append(embedding)\n",
        "        if len(sent_embeddings) > 0:\n",
        "            sentence_embedding = torch.stack(sent_embeddings).mean(dim=0)\n",
        "            sentence_embeddings.append(sentence_embedding)\n",
        "    return sentence_embeddings\n"
      ],
      "metadata": {
        "id": "oTyp9Fy7n3PS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jm6TlPR5FUc9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_sentence_embeddings('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtT-jTsqn3MG",
        "outputId": "97d219d1-987a-4995-e7ff-fb3ab122b44e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yMFsLURn3JQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkg4dIdZn3GZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0Ocmh8bn3Db"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combined_df1['label'] = combined_df1['label'].str.lower()"
      ],
      "metadata": {
        "id": "y_JaGMqjn3As"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combined_df.head()"
      ],
      "metadata": {
        "id": "aZireNXxn2-E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([ctrl_df,fair_df,gpt_df,gpt3_df,gpt2_df,grover_df,human_df,pplm_df,xlm_df,xlnet_df,instruct_df], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "RyK4O89l1Q0T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df[['Generation']] = combined_df[['Generation']].astype(str)"
      ],
      "metadata": {
        "id": "7ingS9XO3Mcl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combined_df['GenMatrix'] = combined_df[['Generation']].apply(get_sentence_embeddings)\n",
        "# combined_df['GenMatrix'] = combined_df.apply(lambda row: get_sentence_embeddings(row['Generation']), axis=1)\n"
      ],
      "metadata": {
        "id": "K5Oa1gtDCYJ3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combined_df['GenMatrix']\n",
        "# torch.save(combined_df['GenMatrix'], '/content/gdrive/MyDrive/NLP/gen_embeddings.pt')"
      ],
      "metadata": {
        "id": "CjUCuMQkUZrq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df['label'] = combined_df['label'].str.lower()"
      ],
      "metadata": {
        "id": "Wn5CTYvPVrIP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df['GenMatrix'] = torch.load('/content/gdrive/MyDrive/NLP/gen_embeddings.pt')"
      ],
      "metadata": {
        "id": "mSmS-O8fv4cB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = torch.load('/content/gdrive/MyDrive/NLP/gen_embeddings.pt')"
      ],
      "metadata": {
        "id": "Ao_uiVsHVqt4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0HMNwHgVqQq",
        "outputId": "7787cd2a-cf48-4b6b-93eb-01fcf10fafe4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([ 5.5902e-01, -1.5989e-01,  2.1612e-01, -2.5526e-02,  1.4165e-01,\n",
              "          5.4916e-02, -3.2942e-01,  2.3700e-03,  4.9956e-01, -1.6809e-01,\n",
              "          2.2704e-01, -3.4573e-01,  1.9350e-01, -8.6950e-02,  6.2820e-01,\n",
              "          3.6054e-02, -3.0480e-01, -4.5010e-02, -2.9259e-01,  4.6916e-02,\n",
              "          3.1867e-03,  1.3723e-01,  2.8357e-01,  4.4388e-03,  2.3751e-01,\n",
              "         -1.5250e+00,  4.1601e-02, -2.4530e-01, -1.3552e-01,  7.8511e-02,\n",
              "          2.6434e+00,  2.8209e-01, -1.0999e-01, -2.7832e-01, -1.0059e-01,\n",
              "         -1.3455e-01,  1.8512e-01,  6.1003e-02, -7.2728e-02,  5.8264e-02,\n",
              "         -5.3455e-01,  2.1291e-02,  6.1507e-01,  1.5536e-01,  4.4793e-01,\n",
              "          1.4188e-02, -5.3610e-01,  1.3268e-01,  1.9627e-01, -2.2344e-01]),\n",
              " tensor([ 0.4802,  0.0527,  0.0179,  0.2030,  0.2559,  0.0311, -0.1485, -0.0743,\n",
              "          0.1972, -0.2133,  0.0678, -0.0927, -0.0995, -0.1768,  0.4216,  0.1769,\n",
              "         -0.3039, -0.1317,  0.0351, -0.0585,  0.0855,  0.0467,  0.3754, -0.1115,\n",
              "          0.2640, -1.2962, -0.1692,  0.0594, -0.1666, -0.0123,  2.4744, -0.0371,\n",
              "         -0.0913, -0.4810, -0.0118, -0.1562,  0.2127,  0.2163, -0.0824,  0.1256,\n",
              "         -0.2086,  0.0816,  0.1660, -0.0815,  0.3568,  0.0582, -0.2690,  0.4129,\n",
              "          0.2213,  0.1148]),\n",
              " tensor([ 0.2354, -0.0975,  0.0378, -0.0563,  0.1225, -0.1046, -0.2195,  0.1255,\n",
              "         -0.0780,  0.1125, -0.2048, -0.0339, -0.4335, -0.0058,  0.3672,  0.2704,\n",
              "          0.2423, -0.2312, -0.1002, -0.4613,  0.0991,  0.1519,  0.0798, -0.0597,\n",
              "          0.3540, -1.6276, -0.2070, -0.0369,  0.3260, -0.1082,  2.9431,  0.4352,\n",
              "         -0.2474, -0.5489, -0.1013, -0.2003, -0.0670,  0.1622, -0.2336, -0.2669,\n",
              "         -0.4149,  0.0227,  0.1695,  0.1796,  0.2369,  0.1455, -0.0851,  0.3564,\n",
              "          0.0568,  0.2045]),\n",
              " tensor([-0.0664,  0.0142,  0.1859, -0.5167,  0.3726, -0.0709, -0.6897, -0.5892,\n",
              "         -0.4927,  0.3473, -0.1642,  0.5684, -0.0452,  0.1289,  0.8597,  0.2660,\n",
              "         -0.2652, -0.0966,  0.2218, -0.6876,  0.0155,  0.3763,  0.4000,  0.5125,\n",
              "          0.6716, -1.4874, -0.9579,  0.0214,  0.1762, -0.7750,  2.9795, -0.1697,\n",
              "         -0.7317, -0.0527, -0.0509, -0.1650,  0.5775, -0.2483, -0.4620, -0.5937,\n",
              "          0.5177,  0.1716, -0.1240,  0.0073, -0.0452,  0.3631,  0.0546, -0.0112,\n",
              "         -0.1612,  0.3938])]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUhirv4JVp55"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "tgcxG3ppCYAV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_matrices = np.array(combined_df['GenMatrix'].values.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iCWUok7IlDj",
        "outputId": "11a01d24-a729-4d21-9c4e-673037326e5f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-5cadcfb371c8>:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  gen_matrices = np.array(combined_df['GenMatrix'].values.tolist())\n",
            "<ipython-input-24-5cadcfb371c8>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  gen_matrices = np.array(combined_df['GenMatrix'].values.tolist())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_matrices[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzrttkxAWivf",
        "outputId": "4c678da7-ed67-4395-a833-e433c8aadeb4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([-0.6388,  0.8221,  0.6981,  0.5711,  0.2418, -0.1767,  0.2791, -0.4686,\n",
              "         -0.3980, -0.2200, -0.1481, -0.0502, -0.4037, -0.2298,  0.2376, -0.1930,\n",
              "          0.0573, -0.4583, -0.6982,  0.0584, -0.0568, -0.4628,  0.5356,  0.0103,\n",
              "         -0.2741, -0.5320,  0.0033, -0.2409,  0.1985,  0.0545,  2.5853,  0.3750,\n",
              "          0.0605,  0.0932, -0.1876, -0.2977,  0.3662, -0.4391,  0.1142,  0.0547,\n",
              "          0.2714, -0.1518,  0.2328, -0.1186, -0.1562,  0.2848,  0.0709,  0.4269,\n",
              "          0.5056,  0.3155]),\n",
              " tensor([ 0.0607,  0.2446,  0.1136,  0.0501,  0.4626, -0.3692, -0.4194, -0.4245,\n",
              "         -0.0517,  0.0305, -0.3850,  0.2517, -0.3255,  0.0917,  0.5974,  0.1086,\n",
              "         -0.3259, -0.5328, -0.0833, -0.3223,  0.5537,  0.2215,  0.1738,  0.4101,\n",
              "          0.4177, -1.3236, -0.4841,  0.0427,  0.0096, -0.3524,  2.7048, -0.1745,\n",
              "         -0.0520, -0.4344, -0.2899, -0.3735, -0.0140, -0.1316, -0.1397, -0.2604,\n",
              "          0.3387,  0.0951,  0.2089,  0.2302,  0.0066,  0.3785,  0.3102,  0.3359,\n",
              "          0.3084,  0.1854]),\n",
              " tensor([ 0.2148, -0.1633,  0.3707,  0.0089,  0.1357, -0.1581, -0.6103, -0.1837,\n",
              "          0.2457, -0.0149, -0.0674,  0.3015, -0.1485, -0.1804,  0.4633,  0.2749,\n",
              "         -0.0269, -0.0935,  0.3785, -0.5587,  0.3186,  0.0901,  0.0130,  0.0731,\n",
              "         -0.0688, -1.5339, -0.2061, -0.2777,  0.2209, -0.4419,  3.0169,  0.3911,\n",
              "         -0.5127, -0.4634, -0.1085, -0.0573,  0.0495,  0.0796,  0.3067, -0.4444,\n",
              "          0.0349, -0.0271,  0.2478,  0.3406, -0.0408,  0.0987, -0.2132,  0.3450,\n",
              "          0.1013,  0.5068]),\n",
              " tensor([ 0.0526, -0.0807,  0.4768,  0.0306,  0.3537, -0.0752, -0.6298, -0.0320,\n",
              "         -0.2100, -0.1009, -0.1171, -0.0890, -0.2805, -0.0419,  0.4397, -0.1217,\n",
              "         -0.3068,  0.0957, -0.2888, -0.3481,  0.1478,  0.2777,  0.2425,  0.2059,\n",
              "          0.3400, -1.0325,  0.0257, -0.0907,  0.2218, -0.2996,  2.4625,  0.2105,\n",
              "         -0.1779, -0.1875, -0.0107,  0.0736,  0.1934,  0.2307,  0.1842, -0.2656,\n",
              "          0.3041, -0.0431, -0.0965,  0.1833,  0.0885,  0.0287,  0.1025,  0.1319,\n",
              "          0.2119,  0.3546]),\n",
              " tensor([ 0.1194,  0.2234,  0.2569, -0.1226,  0.1942,  0.0714, -0.7369, -0.3270,\n",
              "         -0.2727,  0.0973, -0.1170,  0.0311, -0.3550, -0.0831,  0.6700, -0.0182,\n",
              "         -0.2718,  0.1693, -0.2517, -0.3098,  0.0948,  0.0979,  0.0115, -0.0412,\n",
              "          0.1375, -1.2455, -0.2227, -0.1471,  0.3375, -0.1396,  3.1641,  0.0926,\n",
              "         -0.1516,  0.0186,  0.1441,  0.0876,  0.1372,  0.3402,  0.1910, -0.3684,\n",
              "         -0.1576, -0.0469,  0.0596,  0.1150, -0.0906,  0.2678, -0.0520, -0.2882,\n",
              "         -0.1165,  0.1249]),\n",
              " tensor([ 0.3716,  0.0963, -0.0567,  0.1788,  0.5891, -0.6218, -0.4999,  0.3395,\n",
              "         -0.6383, -0.3235, -0.2460, -0.3359, -0.5821, -0.3904,  1.2354,  0.5210,\n",
              "         -0.1695,  0.1048, -0.4558, -0.0945,  0.1094,  0.4602,  0.2544,  0.1390,\n",
              "          0.9347, -1.5348, -0.8688,  0.3292,  0.5610, -0.1388,  2.8296,  0.0355,\n",
              "         -0.0982, -0.4650, -0.1139, -0.5120,  0.1666,  0.0317,  0.2227,  0.3043,\n",
              "         -0.7651, -0.1297,  0.1550,  0.0593, -0.0227,  0.4330, -0.1849,  0.2730,\n",
              "          0.1761,  0.2714])]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.head()"
      ],
      "metadata": {
        "id": "e76lnaBCWjH5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "651c2203-330c-4acc-dd79-c7c77b366c90"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Generation label  \\\n",
              "0  latest headlines on cnn business tl;dr the u.s...  ctrl   \n",
              "1  china wants to take a victory lap over its han...  ctrl   \n",
              "2  coronavirus disinformation creates challenges ...  ctrl   \n",
              "3  china coronavirus: eating wild animals made il...  ctrl   \n",
              "4  china's economy could shrink for the first tim...  ctrl   \n",
              "\n",
              "                                           GenMatrix  \n",
              "0  [[tensor(-0.6388), tensor(0.8221), tensor(0.69...  \n",
              "1  [[tensor(0.5590), tensor(-0.1599), tensor(0.21...  \n",
              "2  [[tensor(0.5684), tensor(-0.1209), tensor(0.13...  \n",
              "3  [[tensor(0.5481), tensor(-0.2022), tensor(-0.1...  \n",
              "4  [[tensor(0.2362), tensor(0.1218), tensor(0.078...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cd4bf57-7ce5-4553-b518-f4adb8246f42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Generation</th>\n",
              "      <th>label</th>\n",
              "      <th>GenMatrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>latest headlines on cnn business tl;dr the u.s...</td>\n",
              "      <td>ctrl</td>\n",
              "      <td>[[tensor(-0.6388), tensor(0.8221), tensor(0.69...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>china wants to take a victory lap over its han...</td>\n",
              "      <td>ctrl</td>\n",
              "      <td>[[tensor(0.5590), tensor(-0.1599), tensor(0.21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coronavirus disinformation creates challenges ...</td>\n",
              "      <td>ctrl</td>\n",
              "      <td>[[tensor(0.5684), tensor(-0.1209), tensor(0.13...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>china coronavirus: eating wild animals made il...</td>\n",
              "      <td>ctrl</td>\n",
              "      <td>[[tensor(0.5481), tensor(-0.2022), tensor(-0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>china's economy could shrink for the first tim...</td>\n",
              "      <td>ctrl</td>\n",
              "      <td>[[tensor(0.2362), tensor(0.1218), tensor(0.078...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cd4bf57-7ce5-4553-b518-f4adb8246f42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cd4bf57-7ce5-4553-b518-f4adb8246f42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cd4bf57-7ce5-4553-b518-f4adb8246f42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df1 = combined_df[['GenMatrix','label']]"
      ],
      "metadata": {
        "id": "TGgzS10vfeal"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df1['label'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqy15o_ff3BW",
        "outputId": "303d61fc-1664-42ce-9d32-8733406962fa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ctrl', 'fair', 'gpt', 'gpt3', 'gpt2', 'grover', 'human', 'pplm',\n",
              "       'xlm', 'xlnet', 'instructgpt'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ltoi = {l: i for i, l in enumerate(combined_df1['label'].unique())}\n",
        "combined_df1['label1'] = combined_df1['label'].apply(lambda y: ltoi[y])"
      ],
      "metadata": {
        "id": "-bpuElQGgGVX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "# class GenMatrixDataset(Dataset):\n",
        "#     def __init__(self, df):\n",
        "#         self.labels = torch.tensor(df['label1'].values)\n",
        "#         self.gen_matrices = torch.stack([torch.tensor(x) for x in df['GenMatrix'].values])\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.labels)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         label = self.labels[idx]\n",
        "#         gen_matrix = self.gen_matrices[idx]\n",
        "#         return gen_matrix, label\n",
        "\n",
        "class GenMatrixDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        df = df[df['GenMatrix'].str.len() > 0]\n",
        "        self.labels = torch.tensor(df['label1'].values)\n",
        "        # self.labels=[]\n",
        "        self.gen_matrices = []\n",
        "        for x in df['GenMatrix'].values:\n",
        "          if len(x) > 1:\n",
        "            # print(torch.stack(x))\n",
        "            self.gen_matrices.append(torch.stack(x))\n",
        "          else:\n",
        "            # print(x)\n",
        "            if len(x)==1:\n",
        "              self.gen_matrices.append(torch.stack(x))\n",
        "            # print(\"Here\")\n",
        "        \n",
        "        \n",
        "        self.gen_matrices = pad_sequence(self.gen_matrices, batch_first=True)\n",
        "        print(self.gen_matrices.size())\n",
        "        print(len(self.labels))\n",
        "\n",
        "        \n",
        "        # self.gen_matrices = torch.stack(self.gen_matrices)\n",
        "          \n",
        "        # self.gen_matrices = torch.stack([torch.tensor(x[0]) if len(x) == 1 else torch.tensor(x) for x in df['GenMatrix'].values])\n",
        "        # self.gen_matrices = torch.stack([torch.tensor(x) if len(x) > 1 else torch.tensor(x[0]).unsqueeze(0) for x in df['GenMatrix'].values])\n",
        "        # self.gen_matrices = torch.stack([torch.tensor(x) if len(x) > 1 else torch.tensor(x).unsqueeze(0) for x in df['GenMatrix'].values])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.gen_matrices[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "# example usage:\n",
        "# df = ... # your Pandas DataFrame with columns 'label' and 'GenMatrix'\n",
        "dataset = GenMatrixDataset(combined_df1)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "3sNdg_hzIky_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3156ab6-17da-4dc2-87ab-1488863d7902"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11687, 161, 50])\n",
            "11687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class LSTM(nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "#         super(LSTM, self).__init__()\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         h0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)\n",
        "#         c0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)\n",
        "#         out, _ = self.lstm(x, (h0, c0))\n",
        "#         out = self.fc(out[:, -1, :])\n",
        "#         return out\n"
      ],
      "metadata": {
        "id": "hBpRylxAoSW3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        #1. Initialize Embedding Layer\n",
        "        # self.embedding = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_dim, padding_idx = pad_idx)\n",
        "        #2. Initialize LSTM layer\n",
        "        self.lstm = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_dim, num_layers = n_layers, dropout = dropout, bidirectional = bidirectional)\n",
        "        #3. Initialize a fully connected layer with Linear transformation\n",
        "        self.fc = nn.Linear(hidden_dim * n_layers, output_dim)\n",
        "        #4. Initialize Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        #1. Apply embedding layer that matches each word to its vector and apply dropout. Dim [sent_len, batch_size, emb_dim]\n",
        "        # embedding = self.embedding(text)\n",
        "        embedding_dropout = self.dropout(text)\n",
        "        #2. Run the LSTM along the sentences of length sent_len. #output = [sent len, batch size, hid dim * num directions]; #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        output, (hidden,cell) = self.lstm(embedding_dropout)\n",
        "        #3. Concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers and apply dropout\n",
        "        concat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "        hidden = self.dropout(concat)     \n",
        "        return self.fc(hidden)"
      ],
      "metadata": {
        "id": "3dpsgWiYxUmt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_DIM = 161\n",
        "OUTPUT_DIM = 11\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "# PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = LSTM( \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT)"
      ],
      "metadata": {
        "id": "glIeL0hAxnjm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR5d_T_X0ZmB",
        "outputId": "a3f9b9c2-7cee-4fcb-a959-033a14dedd8e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 902,577 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train, test, and validation sets\n",
        "total_len = len(dataset)\n",
        "train_len = int(total_len * 0.8)\n",
        "test_len = int(total_len * 0.1)\n",
        "val_len = total_len - train_len - test_len\n",
        "\n",
        "train_set, test_set, val_set = torch.utils.data.random_split(\n",
        "    dataset, [train_len, test_len, val_len])\n",
        "\n",
        "# Create data loaders for train, test, and validation sets\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "fRI8zvoNoe7o"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiclass_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    # get the index of the highest prediction for each instance\n",
        "    _, preds = torch.max(preds, dim=1)\n",
        "    correct = (preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "AdDzRVNwqP4h"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # initialize the model and optimizer\n",
        "# model = LSTM(input_dim=50, hidden_dim=64, output_dim=11).to(device)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# # train the model\n",
        "# num_epochs = 1\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# for epoch in range(num_epochs):\n",
        "#     running_loss = 0.0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     acc=[]\n",
        "#     for i, (inputs, labels) in enumerate(train_loader):\n",
        "#         inputs = inputs.to(device)\n",
        "#         labels = labels.to(device)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(inputs)\n",
        "#         # print(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         acc.append(multiclass_accuracy(outputs,labels))\n",
        "#         # running_loss += loss.item()\n",
        "#         # _, predicted = torch.max(outputs.data, 1)\n",
        "#         # total += labels.size(0)\n",
        "#         # correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     epoch_loss = running_loss / len(dataloader)\n",
        "#     epoch_acc = sum(acc) / len(acc)\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# initialize the model and optimizer\n",
        "# model = LSTM(input_dim=50, hidden_dim=128, output_dim=11).to(device)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "\n",
        "# train the model\n",
        "num_epochs = 20\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "# move the model to the device\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     running_loss = 0.0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     acc=[]\n",
        "#     for i, (inputs, labels) in enumerate(train_loader):\n",
        "#         inputs = inputs.to(device)\n",
        "#         labels = labels.to(device)\n",
        "#         inputs = torch.transpose(inputs, 0, 1)\n",
        "#         # print(inputs.size())\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(inputs)\n",
        "#         # print(outputs.size())\n",
        "#         # print(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         running_loss += loss.item()\n",
        "\n",
        "#         # acc = multiclass_accuracy(outputs,labels)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     epoch_loss = running_loss / len(train_loader.dataset)\n",
        "#     epoch_acc = correct / total\n",
        "#     print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "#           .format(epoch+1, num_epochs, epoch_loss, 100 * epoch_acc))\n"
      ],
      "metadata": {
        "id": "nMB8ctVHIkh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378ad254-5c77-4c85-e8cc-43dd922ca8e5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(50, 161, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=322, out_features=11, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# train the model\n",
        "num_epochs = 50\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    acc=[]\n",
        "    model.train()\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        inputs = torch.transpose(inputs, 0, 1)\n",
        "        # print(inputs.size())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        # print(outputs.size())\n",
        "        # print(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # acc = multiclass_accuracy(outputs,labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            inputs = torch.transpose(inputs, 0, 1)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "          .format(epoch+1, num_epochs, epoch_loss, 100 * epoch_acc))\n",
        "    print('Epoch [{}/{}], Validation Loss: {:.4f}, Validation Accuracy: {:.2f}%'\n",
        "          .format(epoch+1, num_epochs, val_loss, 100 * val_acc))"
      ],
      "metadata": {
        "id": "NPNQRO4kIkRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6fbd19-b391-4e65-ef79-c15f4d4b24fb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.0352, Accuracy: 58.22%\n",
            "Epoch [1/50], Validation Loss: 0.0325, Validation Accuracy: 62.39%\n",
            "Epoch [2/50], Loss: 0.0350, Accuracy: 57.74%\n",
            "Epoch [2/50], Validation Loss: 0.0332, Validation Accuracy: 61.45%\n",
            "Epoch [3/50], Loss: 0.0344, Accuracy: 59.12%\n",
            "Epoch [3/50], Validation Loss: 0.0317, Validation Accuracy: 62.14%\n",
            "Epoch [4/50], Loss: 0.0342, Accuracy: 59.24%\n",
            "Epoch [4/50], Validation Loss: 0.0315, Validation Accuracy: 63.76%\n",
            "Epoch [5/50], Loss: 0.0337, Accuracy: 59.70%\n",
            "Epoch [5/50], Validation Loss: 0.0329, Validation Accuracy: 61.45%\n",
            "Epoch [6/50], Loss: 0.0337, Accuracy: 59.14%\n",
            "Epoch [6/50], Validation Loss: 0.0313, Validation Accuracy: 64.53%\n",
            "Epoch [7/50], Loss: 0.0331, Accuracy: 60.61%\n",
            "Epoch [7/50], Validation Loss: 0.0320, Validation Accuracy: 62.82%\n",
            "Epoch [8/50], Loss: 0.0328, Accuracy: 60.80%\n",
            "Epoch [8/50], Validation Loss: 0.0307, Validation Accuracy: 65.04%\n",
            "Epoch [9/50], Loss: 0.0325, Accuracy: 61.09%\n",
            "Epoch [9/50], Validation Loss: 0.0308, Validation Accuracy: 65.73%\n",
            "Epoch [10/50], Loss: 0.0324, Accuracy: 61.33%\n",
            "Epoch [10/50], Validation Loss: 0.0315, Validation Accuracy: 64.02%\n",
            "Epoch [11/50], Loss: 0.0320, Accuracy: 61.87%\n",
            "Epoch [11/50], Validation Loss: 0.0329, Validation Accuracy: 62.56%\n",
            "Epoch [12/50], Loss: 0.0316, Accuracy: 62.46%\n",
            "Epoch [12/50], Validation Loss: 0.0327, Validation Accuracy: 62.65%\n",
            "Epoch [13/50], Loss: 0.0318, Accuracy: 62.56%\n",
            "Epoch [13/50], Validation Loss: 0.0334, Validation Accuracy: 61.54%\n",
            "Epoch [14/50], Loss: 0.0315, Accuracy: 62.52%\n",
            "Epoch [14/50], Validation Loss: 0.0345, Validation Accuracy: 60.60%\n",
            "Epoch [15/50], Loss: 0.0313, Accuracy: 62.72%\n",
            "Epoch [15/50], Validation Loss: 0.0368, Validation Accuracy: 58.80%\n",
            "Epoch [16/50], Loss: 0.0310, Accuracy: 63.93%\n",
            "Epoch [16/50], Validation Loss: 0.0327, Validation Accuracy: 62.56%\n",
            "Epoch [17/50], Loss: 0.0307, Accuracy: 63.64%\n",
            "Epoch [17/50], Validation Loss: 0.0340, Validation Accuracy: 60.60%\n",
            "Epoch [18/50], Loss: 0.0311, Accuracy: 62.65%\n",
            "Epoch [18/50], Validation Loss: 0.0345, Validation Accuracy: 61.11%\n",
            "Epoch [19/50], Loss: 0.0303, Accuracy: 64.61%\n",
            "Epoch [19/50], Validation Loss: 0.0364, Validation Accuracy: 59.66%\n",
            "Epoch [20/50], Loss: 0.0303, Accuracy: 63.95%\n",
            "Epoch [20/50], Validation Loss: 0.0343, Validation Accuracy: 60.85%\n",
            "Epoch [21/50], Loss: 0.0300, Accuracy: 64.70%\n",
            "Epoch [21/50], Validation Loss: 0.0368, Validation Accuracy: 59.66%\n",
            "Epoch [22/50], Loss: 0.0294, Accuracy: 65.10%\n",
            "Epoch [22/50], Validation Loss: 0.0395, Validation Accuracy: 57.95%\n",
            "Epoch [23/50], Loss: 0.0296, Accuracy: 64.91%\n",
            "Epoch [23/50], Validation Loss: 0.0340, Validation Accuracy: 62.56%\n",
            "Epoch [24/50], Loss: 0.0294, Accuracy: 64.76%\n",
            "Epoch [24/50], Validation Loss: 0.0450, Validation Accuracy: 52.39%\n",
            "Epoch [25/50], Loss: 0.0295, Accuracy: 64.97%\n",
            "Epoch [25/50], Validation Loss: 0.0392, Validation Accuracy: 56.92%\n",
            "Epoch [26/50], Loss: 0.0292, Accuracy: 65.48%\n",
            "Epoch [26/50], Validation Loss: 0.0439, Validation Accuracy: 54.36%\n",
            "Epoch [27/50], Loss: 0.0290, Accuracy: 65.49%\n",
            "Epoch [27/50], Validation Loss: 0.0401, Validation Accuracy: 55.56%\n",
            "Epoch [28/50], Loss: 0.0288, Accuracy: 66.03%\n",
            "Epoch [28/50], Validation Loss: 0.0435, Validation Accuracy: 55.38%\n",
            "Epoch [29/50], Loss: 0.0291, Accuracy: 65.02%\n",
            "Epoch [29/50], Validation Loss: 0.0374, Validation Accuracy: 58.29%\n",
            "Epoch [30/50], Loss: 0.0283, Accuracy: 66.56%\n",
            "Epoch [30/50], Validation Loss: 0.0458, Validation Accuracy: 53.25%\n",
            "Epoch [31/50], Loss: 0.0285, Accuracy: 66.38%\n",
            "Epoch [31/50], Validation Loss: 0.0439, Validation Accuracy: 53.16%\n",
            "Epoch [32/50], Loss: 0.0280, Accuracy: 67.08%\n",
            "Epoch [32/50], Validation Loss: 0.0469, Validation Accuracy: 51.20%\n",
            "Epoch [33/50], Loss: 0.0282, Accuracy: 66.46%\n",
            "Epoch [33/50], Validation Loss: 0.0416, Validation Accuracy: 55.38%\n",
            "Epoch [34/50], Loss: 0.0278, Accuracy: 66.66%\n",
            "Epoch [34/50], Validation Loss: 0.0430, Validation Accuracy: 54.87%\n",
            "Epoch [35/50], Loss: 0.0277, Accuracy: 67.17%\n",
            "Epoch [35/50], Validation Loss: 0.0443, Validation Accuracy: 53.08%\n",
            "Epoch [36/50], Loss: 0.0274, Accuracy: 67.28%\n",
            "Epoch [36/50], Validation Loss: 0.0441, Validation Accuracy: 53.42%\n",
            "Epoch [37/50], Loss: 0.0272, Accuracy: 67.61%\n",
            "Epoch [37/50], Validation Loss: 0.0496, Validation Accuracy: 49.83%\n",
            "Epoch [38/50], Loss: 0.0271, Accuracy: 67.85%\n",
            "Epoch [38/50], Validation Loss: 0.0478, Validation Accuracy: 52.31%\n",
            "Epoch [39/50], Loss: 0.0269, Accuracy: 68.09%\n",
            "Epoch [39/50], Validation Loss: 0.0490, Validation Accuracy: 50.94%\n",
            "Epoch [40/50], Loss: 0.0273, Accuracy: 67.65%\n",
            "Epoch [40/50], Validation Loss: 0.0521, Validation Accuracy: 49.83%\n",
            "Epoch [41/50], Loss: 0.0271, Accuracy: 67.80%\n",
            "Epoch [41/50], Validation Loss: 0.0485, Validation Accuracy: 51.28%\n",
            "Epoch [42/50], Loss: 0.0267, Accuracy: 67.89%\n",
            "Epoch [42/50], Validation Loss: 0.0546, Validation Accuracy: 47.61%\n",
            "Epoch [43/50], Loss: 0.0268, Accuracy: 68.30%\n",
            "Epoch [43/50], Validation Loss: 0.0566, Validation Accuracy: 46.41%\n",
            "Epoch [44/50], Loss: 0.0265, Accuracy: 68.25%\n",
            "Epoch [44/50], Validation Loss: 0.0528, Validation Accuracy: 48.55%\n",
            "Epoch [45/50], Loss: 0.0269, Accuracy: 67.83%\n",
            "Epoch [45/50], Validation Loss: 0.0497, Validation Accuracy: 50.60%\n",
            "Epoch [46/50], Loss: 0.0260, Accuracy: 68.76%\n",
            "Epoch [46/50], Validation Loss: 0.0481, Validation Accuracy: 50.77%\n",
            "Epoch [47/50], Loss: 0.0262, Accuracy: 69.02%\n",
            "Epoch [47/50], Validation Loss: 0.0573, Validation Accuracy: 46.50%\n",
            "Epoch [48/50], Loss: 0.0260, Accuracy: 69.45%\n",
            "Epoch [48/50], Validation Loss: 0.0542, Validation Accuracy: 49.49%\n",
            "Epoch [49/50], Loss: 0.0258, Accuracy: 69.61%\n",
            "Epoch [49/50], Validation Loss: 0.0498, Validation Accuracy: 50.68%\n",
            "Epoch [50/50], Loss: 0.0258, Accuracy: 69.43%\n",
            "Epoch [50/50], Validation Loss: 0.0566, Validation Accuracy: 47.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # acc=[]\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, (inputs, labels) in enumerate(test_loader):\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          inputs = torch.transpose(inputs, 0, 1)\n",
        "          # print(inputs.size())\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          # print(outputs.size())\n",
        "          # print(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          # loss.backward()\n",
        "          # optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "\n",
        "          # acc = multiclass_accuracy(outputs,labels)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(test_loader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "          .format(epoch+1, num_epochs, epoch_loss, 100 * epoch_acc))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def evaluate(model, iterator, criterion):\n",
        "    \n",
        "#     epoch_loss = 0\n",
        "#     epoch_acc = 0\n",
        "    \n",
        "#     model.eval()\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "    \n",
        "#         for batch in iterator:\n",
        "            \n",
        "#             text, text_lengths = batch.text\n",
        "            \n",
        "#             predictions = model(text, text_lengths).squeeze(1)\n",
        "#             target = batch.label\n",
        "#             target = target.type(torch.LongTensor)\n",
        "            \n",
        "#             loss = criterion(predictions.to(device), target.to(device))\n",
        "            \n",
        "#             acc = multiclass_accuracy(predictions, batch.label)\n",
        "\n",
        "#             epoch_loss += loss.item()\n",
        "#             epoch_acc += acc.item()\n",
        "\n",
        "\n",
        "\n",
        "#     return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "wqsA_SrseswS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3fb906-4134-4db0-8fbd-7f36e47f5dd4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.0565, Accuracy: 45.46%\n",
            "Epoch [2/50], Loss: 0.0564, Accuracy: 45.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/gdrive/MyDrive/NLP/sentence_level_model.pt')\n"
      ],
      "metadata": {
        "id": "GMA7nn1R5pz0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u481_meK5pkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9wmzZvy5pUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RoXEVmbu5pEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nEVM_ytx5o0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aj0qx8cL5olJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PyAw4OvU5oVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ej39b84d5oGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hzq50S375n2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eNVKmI_75nnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f-stAyr05nYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G_3-JDfi5nJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_DIM = 161\n",
        "OUTPUT_DIM = 11\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "# PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model1 = LSTM( \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT)"
      ],
      "metadata": {
        "id": "GEVNubVlestB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# initialize the model and optimizer\n",
        "# model = LSTM(input_dim=50, hidden_dim=128, output_dim=11).to(device)\n",
        "model1 = model1.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "\n",
        "# train the model\n",
        "num_epochs = 20\n",
        "# criterion = nn.CrossEntropyLoss().to(device)\n",
        "criterion = nn.NLLLoss().to(device)\n",
        "\n",
        "\n",
        "\n",
        "# move the model to the device\n",
        "model1.to(device)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    acc=[]\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        inputs = torch.transpose(inputs, 0, 1)\n",
        "        # print(inputs.size())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model1(inputs)\n",
        "        # print(outputs.size())\n",
        "        # print(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # acc = multiclass_accuracy(outputs,labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "          .format(epoch+1, num_epochs, epoch_loss, 100 * epoch_acc))\n"
      ],
      "metadata": {
        "id": "HyP7Zhbyespw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K1-9u2acesmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5KDT-jUesjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPmCR6WAesfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eUy0qhXRescL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gN9KrHggesY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUs69DmNesVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JrAmVTcOesSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VXjHDM2aIkAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jxwGxWWpsiE8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}